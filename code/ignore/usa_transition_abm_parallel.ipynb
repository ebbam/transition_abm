{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2137f9",
   "metadata": {},
   "source": [
    "# Micro- (and hopefully soon geo-) Founded Occupational Mobility Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee95600",
   "metadata": {},
   "source": [
    "*Setup from @rmaria del rio-chanona et al. 2021*\n",
    "*Code: @ebbamark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329d5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as random\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "from scipy.interpolate import splrep, BSpline\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "from multiprocessing.pool import Pool\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import multiprocessing as mp\n",
    "import ipyparallel as ipp\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "path = \"~/Documents/Documents - Nuff-Malham/GitHub/transition_abm/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2ff4c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390447b0",
   "metadata": {},
   "source": [
    "### Agents and Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f3e0f",
   "metadata": {},
   "source": [
    "One function and three classes are defined:\n",
    "- (Function) Utility/decision-making function used by workers when deciding which vacancies to apply to.\n",
    "- (Class) Worker: individual worker has state-specific attributes (whether or not employed, current or latest held occupation, time employed or unemployed, current or latest wage held, whether or not they have been hired in a particular time step) and character-specific attributes (occupational history, risk aversion score (not yet implemented) and an impatience score (not yet used)). Worker has one function which is to search and apply for a vacancy.\n",
    "- (Class) Occupation has an id, list of workers currently employed in that occupation, list of neighboring occupations based on transition adjacency matrix (imperfect solution), current and target demand for labour, list of applicants to open vacancies, and wage). Occupation has two internal functions (1) to separate workers and (2) to update all workers in an occupation after each time step.\n",
    "- (Class) Vacancy has an occupational id, list of applicants (duplicated above in occupation class...to fix), and a wage (duplicated above in occupation class...to fix). Vacancy has one internal function to hire an applicant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312cdd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file funs.py\n",
    "## Defining functions\n",
    "# Ranking utility/decision-making function\n",
    "def util(w_current, w_offered, skill_sim):\n",
    "    # No longer scale by impatience\n",
    "    # return 1/(1+(math.exp(-impatience_factor*((w_offered-(w_current*(1-skill_sim)))/10000))))\n",
    "    return 1/(1+(math.exp(-((w_offered - w_current)/10000))))\n",
    "\n",
    "# Simple quadratic for now in which a worker increase search effort for a period of 6 time steps (ie. months) \n",
    "# unemployed after which a worker begins to become discouraged. \n",
    "# This follows definition from the US BLS and Pew Research Centre\n",
    "def search_effort(t_unemp):\n",
    "    return round(20/((t_unemp-6)**2 + 1)) + 1\n",
    "\n",
    "## Defining classes\n",
    "# Potentially redundant use of IDs in the below classes...to check\n",
    "class worker:\n",
    "    def __init__(wrkr, occupation_id, employed, longterm_unemp, time_employed,\n",
    "                 time_unemployed, wage, hired, list_of_occs, risk_av_score):\n",
    "        # State-specific attributes:\n",
    "        # Occupation id\n",
    "        wrkr.occupation_id = occupation_id\n",
    "        # Binary variable for whether employed or not\n",
    "        wrkr.employed = employed\n",
    "        # Binary variable for whether long-term unemployed\n",
    "        wrkr.longterm_unemp = longterm_unemp\n",
    "        # Number of time steps employed\n",
    "        wrkr.time_employed = time_employed\n",
    "        # Number of time steps unemployed (perhaps redundant with above)\n",
    "        # Used as criteria for impatience\n",
    "        wrkr.time_unemployed = time_unemployed\n",
    "        # Worker wage\n",
    "        # Could be used as additional criteria for impatience...\n",
    "        wrkr.wage = wage\n",
    "        # Whether the worker has been hired in this time step - reset to zero at the end of every time step\n",
    "        # Used as protective attribute in hiring process (ie. cannot be hired twice)\n",
    "        wrkr.hired = hired\n",
    "        \n",
    "        # Character-specific attributes:\n",
    "        # Employment history, list of occupations previously held\n",
    "        # NOT YET USED\n",
    "        wrkr.emp_history = list_of_occs\n",
    "        # Identity score - to be defined...\n",
    "        # wrkr.identity = identity_score\n",
    "        # Risk aversion: Stefi suggested to use number of \n",
    "        # occupations previously held as proxy ie. len(emp_history)\n",
    "        # Currently takes a value 0-9 indicating at which index of utility ranked vacancies to start sampling/slicing\n",
    "        wrkr.risk_aversion = risk_av_score\n",
    "    \n",
    "    def search_and_apply(wrkr, net, vac_list, beh):\n",
    "        # A sample of relevant vacancies are found that are in neighboring occupations\n",
    "        # Will need to add a qualifier in case sample is greater than available relevant vacancies\n",
    "        # ^^ have added qualifier...bad form to reassign list?\n",
    "        rel_vacs = [vac for vac in vac_list if net[wrkr.occupation_id].list_of_neigh_bool[vac.occupation_id]]\n",
    "        if beh:\n",
    "            rel_vacs = random.sample(rel_vacs, min(len(rel_vacs), 30))\n",
    "            # Sort found relevant vacancies by utility-function defined above and apply to amount dictated by impatience\n",
    "            for v in sorted(rel_vacs, key = lambda v: util(wrkr.wage, v.wage,net[wrkr.occupation_id].list_of_neigh_weights[v.occupation_id]), reverse = True)[slice(wrkr.risk_aversion, wrkr.risk_aversion + search_effort(wrkr.time_unemployed))]:\n",
    "                # Introduce randomness here...binomial?\n",
    "                v.applicants.append(wrkr)\n",
    "        else:\n",
    "            rel_vacs = random.sample(rel_vacs, min(len(rel_vacs), search_effort(wrkr.time_unemployed)))\n",
    "            for r in rel_vacs:\n",
    "                r.applicants.append(wrkr)\n",
    "            \n",
    "class occupation:\n",
    "    def __init__(occ, occupation_id, list_of_workers, list_of_neigh_bool, \n",
    "                 list_of_neigh_weights, current_demand, \n",
    "                 target_demand, applicants, wage):\n",
    "        occ.occupation_id = occupation_id\n",
    "        occ.list_of_workers = list_of_workers\n",
    "        occ.list_of_neigh_bool = list_of_neigh_bool\n",
    "        occ.list_of_neigh_weights = list_of_neigh_weights\n",
    "        occ.current_demand = current_demand\n",
    "        occ.target_demand = target_demand\n",
    "        occ.applicants = applicants\n",
    "        occ.wage = wage\n",
    "    \n",
    "    def separate_workers(occ):\n",
    "        if(len(occ.list_of_workers) != 0):\n",
    "            sep_prob = delta_u + gamma * max(0, occ.current_demand - occ.target_demand)/(sum(wrkr.employed for wrkr in occ.list_of_workers) + 1)\n",
    "            emp = [el for el in occ.list_of_workers if el.employed]\n",
    "            sep_counter = 0\n",
    "            for w in random.sample(emp, np.random.binomial(len(emp), sep_prob)):\n",
    "                w.employed = False\n",
    "                w.longterm_unemp = False\n",
    "                w.time_employed = 0\n",
    "                w.time_unemployed = 0\n",
    "                sep_counter += 1\n",
    "    \n",
    "    def update_workers(occ):\n",
    "        for w in occ.list_of_workers:\n",
    "            # Must update hired attribute of workers\n",
    "            w.hired = False\n",
    "            if w.employed:\n",
    "                w.time_employed += 1\n",
    "            if not(w.employed):\n",
    "                w.time_unemployed += 1\n",
    "                w.longterm_unemp = True if w.time_unemployed >= 7 else False\n",
    "                #don’t w.search_effort = search_effort(w.time_unemployed)\n",
    "                \n",
    "        \n",
    "class vac:\n",
    "    def __init__(v, occupation_id, applicants, wage):\n",
    "        v.occupation_id = occupation_id\n",
    "        v.applicants = applicants\n",
    "        v.wage = wage\n",
    "    def hire(v, net):\n",
    "        a = random.choice([app for app in v.applicants if not(app.hired)])\n",
    "        assert(not(a.employed))\n",
    "        assert(not(a.hired))\n",
    "        net[v.occupation_id].list_of_workers.append(net[a.occupation_id].list_of_workers.pop(net[a.occupation_id].list_of_workers.index(a)))\n",
    "        a.occupation_id = v.occupation_id\n",
    "        a.employed = True\n",
    "        a.longterm_unemp = False\n",
    "        a.time_employed = 0\n",
    "        a.time_unemployed = 0\n",
    "        a.wage = v.wage\n",
    "        a.emp_history.append(v.occupation_id)\n",
    "        a.hired = True\n",
    "        # Reset?\n",
    "        # wrkr.risk_aversion = risk_av_score\n",
    "        # Reset?\n",
    "        # wrkr.impatience = impatience_score\n",
    "        v.applicants.clear()\n",
    "\n",
    "        \n",
    "def bus_cycle_demand(d_0, time, amp, period):\n",
    "    \"\"\"function that target demand of time t of sigmoid shock with parameters\n",
    "    Args:\n",
    "        d_0: vector of initial demand of occupation\n",
    "        d_final: (ignored)\n",
    "        amplitude: amplitude of business cycle\n",
    "        period: period for full business cycle\n",
    "    Returns\n",
    "        d_dagger(Array{Float64,2}): demand of occupation at time t\n",
    "    \"\"\"\n",
    "#     if t < t_shock:\n",
    "#         return d_0\n",
    "#    else:\n",
    "        # start cycle when shock starts\n",
    "        #t0 = t + t_shock\n",
    "    d_target =  d_0 * (1 - amp * np.sin((2*np.pi / period) * time))\n",
    "    return d_target\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346702b0",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388e404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make global decision as to which data to initialise network on. Current options are \"toy\" or \"USA\"\n",
    "#init = \"toy\"\n",
    "# behav = False\n",
    "#shock = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70823b6",
   "metadata": {},
   "source": [
    "#### Toy Model\n",
    "Toy model constructed on 5 fake occupations with pre-determined employment, unemployment, vacancies, target demand, and wages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d87718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting toy_init.py\n"
     ]
    }
   ],
   "source": [
    "%%file toy_init.py\n",
    "\n",
    "T = 1000\n",
    "delta_u = 0.01\n",
    "delta_v = 0.005\n",
    "gamma_u = gamma_v = gamma = 0.01\n",
    "# Import information about relevant files to employment/unemployment, target demand, vacancies, etc.\n",
    "\n",
    "A = pd.read_csv(path+\"data/small_adj_full.csv\", delimiter=';', decimal=',', header=None)\n",
    "employment = pd.read_csv(path+\"data/employed.csv\", header = None)\n",
    "unemployment = pd.read_csv(path+\"data/unemployed.csv\", header = None)\n",
    "vacancies = pd.read_csv(path+\"data/vacancies.csv\", header = None)\n",
    "demand_target = employment + vacancies\n",
    "wages = pd.DataFrame(np.round(np.random.normal(50000, 10000, 5)), columns = ['Wages'])\n",
    "mod_data =  {\"A\": A, \"employment\": employment, \n",
    "             'unemployment':unemployment, 'vacancies':vacancies, \n",
    "             'demand_target': demand_target, 'wages': wages}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8849f",
   "metadata": {},
   "source": [
    "#### US Model\n",
    "Model constructed using 464 occupations from US Bureau of Labor Statistics Data and IPUMS.\n",
    "Data input from replicaiton code in dRC et al 2021: https://zenodo.org/records/4453162\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9fba2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting us_init.py\n"
     ]
    }
   ],
   "source": [
    "%%file us_init.py\n",
    "\n",
    "###################################\n",
    "# INITIAL MODEL CONDITIONS ########\n",
    "###################################\n",
    "T = 45\n",
    "delta_u = 0.015\n",
    "delta_v = 0.01\n",
    "gamma_u = gamma_v = gamma = 0.06\n",
    "\n",
    "A = pd.read_csv(path+\"dRC_Replication/data/occupational_mobility_network.csv\", header=None)\n",
    "employment = round(pd.read_csv(path+\"dRC_Replication/data/ipums_employment_2016.csv\", header = 0).iloc[:, [4]]/1000)\n",
    "# Crude approximation using avg unemployment rate of ~5% - should aim for occupation-specific unemployment rates\n",
    "unemployment = round(employment*(0.05/0.95))\n",
    "# Less crude approximation using avg vacancy rate - should still aim for occupation-specific vacancy rates\n",
    "vac_rate_base = pd.read_csv(path+\"dRC_Replication/data/vacancy_rateDec2000.csv\").iloc[:, 2].mean()/100\n",
    "vacancies = round(employment*vac_rate_base/(1-vac_rate_base))\n",
    "# Needs input data...\n",
    "demand_target = employment + vacancies\n",
    "wages = pd.read_csv(path+\"dRC_Replication/data/ipums_variables.csv\")[['median_earnings']]\n",
    "mod_data =  {\"A\": A, \"employment\": employment, \n",
    "             'unemployment':unemployment, 'vacancies':vacancies, \n",
    "             'demand_target': demand_target, 'wages': wages}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7aee7",
   "metadata": {},
   "source": [
    "### Initialise Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33329d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting init.py\n"
     ]
    }
   ],
   "source": [
    "%%file init.py\n",
    "### Function and condition to initialise network\n",
    "\n",
    "def initialise(n_occ, employment, unemployment, vacancies, demand_target, A, wages):\n",
    "    \"\"\" Makes a list of occupations with initial conditions\n",
    "       Args:\n",
    "           n_occ: number of occupations initialised\n",
    "           employment: vector with employment of each occupation\n",
    "           unemployment: vector with unemployment of each occupation\n",
    "           vacancies: vector with vacancies of each occupation\n",
    "           demand_target: vector with (initial) target_demand for each occupation (never updated)\n",
    "           A: adjacency matrix of network (not including auto-transition probability)\n",
    "           wages: vector of wages of each occupation\n",
    "\n",
    "       Returns:\n",
    "            occupations: list of occupations with above attributes\n",
    "            vacancies: list of vacancies with occupation id, wage, and list of applicants\n",
    "       \"\"\"\n",
    "    occs = []\n",
    "    vac_list = []\n",
    "    ids = 0\n",
    "    for i in range(0, n_occ):\n",
    "        # appending relevant number of vacancies to economy-wide vacancy list\n",
    "        for v in range(round(vacancies.iat[i,0])):\n",
    "            vac_list.append(vac(i, [], wages.iat[i,0]))\n",
    "            \n",
    "        occ = occupation(i, [], A[i] > 0, A[i],\n",
    "                         (employment.iat[i,0] + vacancies.iat[i,0]), \n",
    "                         demand_target.iat[i,0], [], wages.iat[i,0])\n",
    "        # creating the workers of occupation i and attaching to occupation\n",
    "        ## adding employed workers\n",
    "        for e in range(round(employment.iat[i,0])):\n",
    "            # Assume they have all at least 1 t.s. of employment\n",
    "            occ.list_of_workers.append(worker(occ.occupation_id, True, False, 1, 0, wages.iat[i,0], False, [occ.occupation_id], random.randint(0, 9)))\n",
    "            ## adding unemployed workers\n",
    "            # Could consider adding random initial unemployment durations...for now no one becomes longterm unemployed until 6 time steps in\n",
    "        for u in range(round(unemployment.iat[i,0])):\n",
    "            # Assigns time unemployed from absolute value of normal distribution....\n",
    "            occ.list_of_workers.append(worker(occ.occupation_id, False, False, 0, abs(int(np.random.normal(0, 2))), wages.iat[i,0], False,\n",
    "                                                     [occ.occupation_id], \n",
    "                                                      random.randint(0, 9)))\n",
    "        occs.append(occ)\n",
    "        ids += 1\n",
    "    return occs, vac_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064bce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Testing Cell #####\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe09d1d",
   "metadata": {},
   "source": [
    "## Model Run\n",
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a596706",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Model Run ########\n",
    "####################\n",
    "def run_sim(behav_spec, data, time_steps, runs):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # Records variables of interest\n",
    "    record = pd.DataFrame(columns=['Sim', 'Time', 'Occupation_ID', 'Workers', 'Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand'])\n",
    "    print(record)\n",
    "    for run in range(runs):\n",
    "        #print(\"Running \", init, \" model.\")\n",
    "        print(\"RUN: \", run)\n",
    "        # Initialise occupational mobility network\n",
    "        net_temp, vacs = initialise(len(data['A']), data['employment'], data['unemployment'], data['vacancies'], data['demand_target'], data['A'], data['wages'])\n",
    "        for t in range(time_steps):\n",
    "            print(\"TIME: \", t)\n",
    "            if t == 400 and shock:\n",
    "                print(\"initiatied shock!\")\n",
    "                net_temp[0].target_demand += 25\n",
    "                net_temp[1].target_demand += 50\n",
    "                net_temp[2].target_demand += 50\n",
    "                net_temp[3].target_demand += 50\n",
    "                net_temp[4].target_demand = 100\n",
    "\n",
    "            # Ensure number of workers in economy has not changed\n",
    "            assert(sum(map(lambda x: len(x.list_of_workers), net_temp)) == employment.sum().item() + unemployment.sum().item())\n",
    "            for occ in net_temp:\n",
    "\n",
    "                ### SEPARATIONS\n",
    "                occ.separate_workers()\n",
    "\n",
    "                # Ensure that separated workers have been reassigned appropriately \n",
    "                # (ie. that people move witihin the same occupation from employed to unemployed \n",
    "                # and that the total number of workers iwthin an occupation is (at this stage) \n",
    "                # the same as before separations\n",
    "                if t > 0:\n",
    "                    temp = record.loc[(record['Sim'] == run) & (record['Occupation_ID'] == occ.occupation_id) & (record['Time'] == t-1)]\n",
    "                    assert(temp.Employment.item() - sum(wrkr.employed for wrkr in occ.list_of_workers) ==\n",
    "                           sum(not(wrkr.employed) for wrkr in occ.list_of_workers) - temp.Unemployment.item())\n",
    "                    assert(len(occ.list_of_workers) == temp.Workers.item())\n",
    "\n",
    "                ### APPLICATIONS\n",
    "                # Questions to verify:\n",
    "                # - CANNOT be fired and apply in same time step ie. time_unemployed > 0\n",
    "                # - CAN be rejected and apply in the same time step - no protected attribute\n",
    "                unemp = [el for el in occ.list_of_workers if not(el.employed) and el.time_unemployed > 0]\n",
    "                for u in unemp:\n",
    "                    u.search_and_apply(net_temp, vacs, behav_spec)\n",
    "\n",
    "            ### HIRING\n",
    "            # Ordering of hiring randomised to ensure list order does not matter in filling vacancies...\n",
    "            # ....might be better to do this using an unordered set?\n",
    "            for v_open in sorted(vacs,key=lambda _: random.random()):\n",
    "                # Removes any applicants that have already been hired in another vacancy\n",
    "                v_open.applicants[:] = [app for app in v_open.applicants if not(app.hired)]\n",
    "                                    print(len(v_open.applicants) == len([app for app in v_open.applicants if not(app.hired)]))\n",
    "                if len([app for app in v_open.applicants if not(app.hired)]) > 0:\n",
    "\n",
    "                    v_open.hire(net_temp)\n",
    "                    vacs.remove(v_open)\n",
    "                    assert(len(v_open.applicants) == 0)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            ### OPEN VACANCIES\n",
    "            # Update vacancies after all shifts have taken place\n",
    "            # Could consider making this a function of the class itself\n",
    "            for occ in net_temp:\n",
    "                # Update all workers\n",
    "                occ.update_workers()\n",
    "                emp = sum(wrkr.employed for wrkr in occ.list_of_workers)\n",
    "                occ.current_demand = bus_cycle_demand(len([v_open for v_open in vacs if v_open.occupation_id == occ.occupation_id]) + emp, t, 0.9, 15)\n",
    "                vac_prob = delta_v + ((1 - delta_v) * (gamma * max(0, occ.target_demand - occ.current_demand))) / (emp + 1)\n",
    "                print(\"Employment\", emp)\n",
    "                print(\"Vacancy probability:\", vac_prob)\n",
    "                for v in range(int(np.random.binomial(emp, vac_prob))):\n",
    "                    vacs.append(vac(occ.occupation_id, [], occ.wage))\n",
    "\n",
    "                ### UPDATE INDICATOR RECORD\n",
    "                # Record of indicators of interest (simulation number, occ, # workers, employed, unemployed, vacancies, long_term_unemployed)\n",
    "                record.loc[len(record)]= [run, \n",
    "                                          t,\n",
    "                                          occ.occupation_id,\n",
    "                                          len(occ.list_of_workers),\n",
    "                                          sum(wrkr.employed for wrkr in occ.list_of_workers),\n",
    "                                          sum(not(wrkr.employed) for wrkr in occ.list_of_workers),\n",
    "                                          len([v_open for v_open in vacs if v_open.occupation_id == occ.occupation_id]),\n",
    "                                          sum(wrkr.longterm_unemp for wrkr in occ.list_of_workers),\n",
    "                                          occ.target_demand]\n",
    "\n",
    "        print(\"Done after \", t + 1, \" time steps.\")\n",
    "    print(\"Done after \", run + 1, \" time steps.\")\n",
    "    return(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca715590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 4 engines with <class 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'>\n",
      "  0%|                                                 | 0/4 [00:00<?, ?engine/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m cluster\u001b[38;5;241m.\u001b[39mstart_cluster_sync()\n\u001b[1;32m      5\u001b[0m rc \u001b[38;5;241m=\u001b[39m cluster\u001b[38;5;241m.\u001b[39mconnect_client_sync()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_engines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m direct \u001b[38;5;241m=\u001b[39m rc[:] \u001b[38;5;66;03m# use all engines\u001b[39;00m\n\u001b[1;32m      8\u001b[0m direct\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipyparallel/client/client.py:1605\u001b[0m, in \u001b[0;36mClient.wait_for_engines\u001b[0;34m(self, n, timeout, block, interactive, widget)\u001b[0m\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39madd_callback(schedule_timeout)\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m-> 1605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#sim_record_t_all = run_sim(True, mod_data, T, 1)\n",
    "#request a cluster\n",
    "cluster = ipp.Cluster(n = 4)\n",
    "cluster.start_cluster_sync()\n",
    "rc = cluster.connect_client_sync()\n",
    "rc.wait_for_engines()\n",
    "direct = rc[:] # use all engines\n",
    "direct.block=True\n",
    "direct.run(\"imports.py\")\n",
    "direct.run(\"init.py\")\n",
    "direct.run(\"funs.py\")\n",
    "direct.run(\"toy_init.py\")\n",
    "#direct.run(\"us_init.py\")\n",
    "asyncresult = direct.apply_async(run_sim, True, mod_data, T, 1)\n",
    "#     #asyncresult = view.map_async(lambda x, y: x + y, range(10), range(10))\n",
    "#     # wait interactively for results\n",
    "asyncresult.wait_interactive()\n",
    "#     # retrieve actual results\n",
    "result = asyncresult.get()\n",
    "result  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file funs.py\n",
    "\n",
    "# task_durations = range(12)\n",
    "# def fun_test(k, j):\n",
    "#     return (k**2)*j\n",
    "\n",
    "\n",
    "# import random as random\n",
    "# import matplotlib.pyplot as plt\n",
    "# import math as math\n",
    "# from scipy.interpolate import splrep, BSpline\n",
    "# import seaborn as sns\n",
    "# from IPython import display\n",
    "# from multiprocessing.pool import Pool\n",
    "# from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "# import multiprocessing as mp\n",
    "# import ipyparallel as ipp\n",
    "# rng = np.random.default_rng()\n",
    "\n",
    "#sim_record_t_all = run_sim(True, mod_data, T, 1)\n",
    "#request a cluster\n",
    "# with ipp.Cluster() as rc:\n",
    "#     print(rc.ids)\n",
    "#     %%file myscript.py\n",
    "#     #import sim_code\n",
    "#     # get a view on the cluster\n",
    "#     view = rc.load_balanced_view()\n",
    "#     # submit the tasks\n",
    "#     asyncresult = view.apply_async(run_sim, True, mod_data, T, 1)\n",
    "#     #asyncresult = view.map_async(lambda x, y: x + y, range(10), range(10))\n",
    "#     # wait interactively for results\n",
    "#     asyncresult.wait_interactive()\n",
    "#     # retrieve actual results\n",
    "#     result = asyncresult.get()\n",
    "\n",
    "# result   \n",
    "\n",
    "    \n",
    "# with mp.Pool(processes = 4) as pool:\n",
    "#     res = pool.starmap(fun_test, [(1,2), (10,-1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43eedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_record_f_all = run_sim(False, mod_data, T, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82e73f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c57571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results specifications (whether to save as final or not)\n",
    "final = False\n",
    "sim_record_f_all = sim_record_t_all\n",
    "sim_record_t = sim_record_t_all.loc[(sim_record_t_all.Time > 0)]\n",
    "sim_record_f = sim_record_f_all.loc[(sim_record_f_all.Time > 0)]\n",
    "record1_t = sim_record_t.loc[(sim_record_t.Sim == 0)]\n",
    "record1_f = sim_record_f.loc[(sim_record_f.Sim == 0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cc5214",
   "metadata": {},
   "source": [
    "#### Beveridge curve validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f63939",
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_vac_f = record1_f.loc[:,['Time', 'Workers', 'Unemployment', 'Vacancies', 'Target_Demand']].groupby(['Time']).sum().reset_index()\n",
    "ue_vac_f['UE Rate'] = ue_vac_f['Unemployment'] / ue_vac_f['Workers']\n",
    "ue_vac_f['Vac Rate'] = ue_vac_f['Vacancies'] / ue_vac_f['Target_Demand']\n",
    "ue_vac_f = ue_vac_f.loc[ue_vac_f.Time < 267]\n",
    "\n",
    "ue_vac_t = record1_t.loc[:,['Time', 'Workers', 'Unemployment', 'Vacancies', 'Target_Demand']].groupby(['Time']).sum().reset_index()\n",
    "ue_vac_t['UE Rate'] = ue_vac_t['Unemployment'] / ue_vac_t['Workers']\n",
    "ue_vac_t['Vac Rate'] = ue_vac_t['Vacancies'] / ue_vac_t['Target_Demand']\n",
    "ue_vac_t = ue_vac_t.loc[ue_vac_t.Time < 268]\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "ax1.plot(ue_vac_f['UE Rate'], ue_vac_f['Vac Rate'])\n",
    "ax1.scatter(ue_vac_f['UE Rate'], ue_vac_f['Vac Rate'], c=ue_vac_f['Time'], s=100, lw=0)\n",
    "ax1.set_title(\"Non-behavioural\")\n",
    "ax1.set_xlabel(\"UE Rate\")\n",
    "ax1.set_ylabel(\"Vacancy Rate\")\n",
    "\n",
    "ax2.plot(ue_vac_t['UE Rate'], ue_vac_t['Vac Rate'])\n",
    "ax2.set_title(\"Behavioural\")\n",
    "ax2.scatter(ue_vac_t['UE Rate'], ue_vac_t['Vac Rate'], c=ue_vac_t['Time'], s=100, lw=0)\n",
    "ax2.set_xlabel(\"UE Rate\")\n",
    "ax2.set_ylabel(\"Vacancy Rate\")\n",
    "\n",
    "    \n",
    "fig.suptitle(\"USA Model Beveridge Curve\", fontweight = 'bold')\n",
    "fig.tight_layout()\n",
    "\n",
    "# if final:\n",
    "#     plt.savefig('../output/overall_economy_comparison_behav.jpg', dpi = 300)\n",
    "# else:\n",
    "#     plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8828e",
   "metadata": {},
   "source": [
    "#### Overall Economy: Employment, Unemployment, Worker, Vacancy, and Longterm Employed Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd06f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Indicators in overall economy\n",
    "# totals = record1_f.loc[:,['Time', 'Workers','Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']].groupby(['Time']).sum()\n",
    "# lgd = []\n",
    "# for column in totals[1:]:\n",
    "#     plt.plot(totals[column])\n",
    "#     lgd.append(column)\n",
    "#     plt.legend(list(lgd), loc=\"center\", ncol=1)\n",
    "# plt.title(\"Overall Economy Performance: Indicators over Time\", fontweight = 'bold')\n",
    "# if final:\n",
    "#     plt.savefig('../output/overall_economy_base.jpg', dpi = 300)\n",
    "# else:\n",
    "#     plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e141675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "totals = record1_f.loc[:,['Time', 'Workers','Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']].groupby(['Time']).sum()\n",
    "lgd = []\n",
    "for column in totals[1:]:\n",
    "    ax1.plot(totals[column])\n",
    "    lgd.append(column)\n",
    "ax1.set_title(\"Non-behavioural\")\n",
    "    \n",
    "totals = record1_t.loc[:,['Time', 'Workers','Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']].groupby(['Time']).sum()\n",
    "for column in totals[1:]:\n",
    "    ax2.plot(totals[column])\n",
    "ax2.set_title('Behavioural')\n",
    "\n",
    "fig.suptitle(\"Overall Economy Performance: Indicators over Time\", fontweight = 'bold')\n",
    "plt.legend(list(lgd), loc=\"center\", ncol=1, fontsize = 8)\n",
    "fig.tight_layout()\n",
    "\n",
    "if final:\n",
    "    plt.savefig('../output/overall_economy_comparison_behav.jpg', dpi = 300)\n",
    "else:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a95baf",
   "metadata": {},
   "source": [
    "#### Long-term unemployment rate and levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63525eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LT Unemployed per occupation\n",
    "\n",
    "# ltue = record1_t.loc[:,['Time', 'Occupation_ID','Workers', 'LT Unemployed Persons']].groupby(['Time', 'Occupation_ID']).sum().reset_index()\n",
    "# ltue['LTUE Rate'] = ltue['LT Unemployed Persons'] / ltue['Workers']\n",
    "# lgd = []\n",
    "# for g in np.unique(ltue.Occupation_ID):\n",
    "#     temp = ltue[(ltue['Occupation_ID'] == g)][['LTUE Rate', 'Time']]\n",
    "#     plt.plot(temp['Time'], temp['LTUE Rate'])\n",
    "#     lgd.append(int(g))\n",
    "# plt.title(\"LT Unemployment Rate per Occ\", fontweight = 'bold')\n",
    "# plt.legend(list(lgd), loc=\"center left\", ncol=1, title = \"Occ\")\n",
    "# if final:\n",
    "#     plt.savefig('../output/ltuer_occ_base.jpg', dpi = 300)\n",
    "# else:\n",
    "#     plt.show()\n",
    "# plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "# ltue = record1_f.loc[:,['Time', 'Occupation_ID','Workers', 'LT Unemployed Persons']].groupby(['Time', 'Occupation_ID']).sum().reset_index()\n",
    "# ltue['LTUE Rate'] = ltue['LT Unemployed Persons'] / ltue['Workers']\n",
    "# lgd = []\n",
    "# for g in np.unique(ltue.Occupation_ID):\n",
    "#     temp = ltue[(ltue['Occupation_ID'] == g)][['LTUE Rate', 'Time']]\n",
    "#     ax1.plot(temp['Time'], temp['LTUE Rate'])\n",
    "# ax1.set_title(\"Non-behavioural\")\n",
    "\n",
    "# ltue = record1_t.loc[:,['Time', 'Occupation_ID','Workers', 'LT Unemployed Persons']].groupby(['Time', 'Occupation_ID']).sum().reset_index()\n",
    "# ltue['LTUE Rate'] = ltue['LT Unemployed Persons'] / ltue['Workers']\n",
    "# lgd = []\n",
    "# for g in np.unique(ltue.Occupation_ID):\n",
    "#     temp = ltue[(ltue['Occupation_ID'] == g)][['LTUE Rate', 'Time']]\n",
    "#     ax2.plot(temp['Time'], temp['LTUE Rate'])\n",
    "#     lgd.append(int(g))\n",
    "# ax2.set_title('Behavioural')\n",
    "# fig.suptitle(\"LT Unemployment Rate per Occ\", fontweight = 'bold')\n",
    "# fig.tight_layout()\n",
    "\n",
    "\n",
    "# if final:\n",
    "#     plt.savefig('../output/ltuer_occ_comparison_behav.jpg', dpi = 300)\n",
    "# else:\n",
    "#     plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "# colors = ['b','g','r','y','m']\n",
    "\n",
    "# sim_record_f['LTUE Rate'] = sim_record_f['LT Unemployed Persons'] / sim_record_f['Workers']\n",
    "# for o in np.unique(sim_record_f.Occupation_ID):\n",
    "#     temp = sim_record_f[(sim_record_f['Occupation_ID'] == o)][['LTUE Rate', 'Time', 'Sim']]\n",
    "#     temp_mean = temp.loc[:, ['Time', 'LTUE Rate']].groupby(['Time']).mean().reset_index()\n",
    "#     spl = splrep(temp_mean['Time'], temp_mean['LTUE Rate'], s=2)\n",
    "#     for g in np.unique(temp.Sim):\n",
    "#         ax1.plot(temp[(temp['Sim'] == g)]['Time'], temp[(temp['Sim'] == g)]['LTUE Rate'], alpha = 0.05, color = colors[o])\n",
    "#     ax1.plot(temp_mean['Time'], BSpline(*spl)(temp_mean['Time']), '-', color = colors[o])\n",
    "# ax1.set_title(\"Non-behavioural\")\n",
    "# fig.suptitle(\"LT Unemployment Rate\", fontweight = 'bold')\n",
    "\n",
    "# sim_record_t['LTUE Rate'] = sim_record_t['LT Unemployed Persons'] / sim_record_t['Workers']\n",
    "# for o in np.unique(sim_record_t.Occupation_ID):\n",
    "#     temp = sim_record_t[(sim_record_t['Occupation_ID'] == o)][['LTUE Rate', 'Time', 'Sim']]\n",
    "#     temp_mean = temp.loc[:, ['Time', 'LTUE Rate']].groupby(['Time']).mean().reset_index()\n",
    "#     spl = splrep(temp_mean['Time'], temp_mean['LTUE Rate'], s=3)\n",
    "#     for g in np.unique(temp.Sim):\n",
    "#         ax2.plot(temp[(temp['Sim'] == g)]['Time'], temp[(temp['Sim'] == g)]['LTUE Rate'], alpha = 0.05, color = colors[o])\n",
    "#     ax2.plot(temp_mean['Time'], BSpline(*spl)(temp_mean['Time']), '-', color = colors[o])\n",
    "# ax2.set_title(\"Behavioural\")\n",
    "# fig.suptitle(\"LT Unemployment Rate by Occupation\", fontweight = 'bold')\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "# if final:\n",
    "#     plt.savefig('../output/ltuer_sim_comparison_behav.jpg', dpi = 300)\n",
    "# else:\n",
    "#     plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7833a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "colors = colors = ['b','g','r','y','m']\n",
    "\n",
    "sim_record_f['UE Rate'] = sim_record_f['Unemployment'] / sim_record_f['Workers']\n",
    "for o in np.unique(sim_record_f.Occupation_ID):\n",
    "    temp = sim_record_f[(sim_record_f['Occupation_ID'] == o)][['UE Rate', 'Time', 'Sim']]\n",
    "    temp_mean = temp.loc[:, ['Time', 'UE Rate']].groupby(['Time']).mean().reset_index()\n",
    "    spl = splrep(temp_mean['Time'], temp_mean['UE Rate'], s=2)\n",
    "    for g in np.unique(temp.Sim):\n",
    "        ax1.plot(temp[(temp['Sim'] == g)]['Time'], temp[(temp['Sim'] == g)]['UE Rate'], alpha = 0.05, color = colors[o])\n",
    "    ax1.plot(temp_mean['Time'], BSpline(*spl)(temp_mean['Time']), '-', color = colors[o])\n",
    "ax1.set_title(\"Non-behavioural\")\n",
    "fig.suptitle(\"Unemployment Rate\", fontweight = 'bold')\n",
    "\n",
    "sim_record_t['UE Rate'] = sim_record_t['Unemployment'] / sim_record_t['Workers']\n",
    "for o in np.unique(sim_record_t.Occupation_ID):\n",
    "    temp = sim_record_t[(sim_record_t['Occupation_ID'] == o)][['UE Rate', 'Time', 'Sim']]\n",
    "    temp_mean = temp.loc[:, ['Time', 'UE Rate']].groupby(['Time']).mean().reset_index()\n",
    "    spl = splrep(temp_mean['Time'], temp_mean['UE Rate'], s=3)\n",
    "    for g in np.unique(temp.Sim):\n",
    "        ax2.plot(temp[(temp['Sim'] == g)]['Time'], temp[(temp['Sim'] == g)]['UE Rate'], alpha = 0.05, color = colors[o])\n",
    "    ax2.plot(temp_mean['Time'], BSpline(*spl)(temp_mean['Time']), '-', color = colors[o])\n",
    "ax2.set_title(\"Behavioural\")\n",
    "fig.suptitle(\"Unemployment Rate by Occupation\", fontweight = 'bold')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4c1000",
   "metadata": {},
   "source": [
    "#### Occupations: Employment, Unemployment, Worker, Vacancy, and Longterm Unemployed Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7cc308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Overall indicators per occupation\n",
    "# ids = np.unique(record1_t.Occupation_ID)\n",
    "# fig = plt.figure(constrained_layout = False)\n",
    "\n",
    "# occ_totals = record1_t.loc[:,['Time', 'Occupation_ID', 'Workers','Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']]\n",
    "# for occ in ids:\n",
    "#     gtmp = occ_totals[(occ_totals['Occupation_ID'] == occ)].loc[:, ['Time', 'Workers', 'Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']].groupby(['Time']).sum()\n",
    "#     # Indicators (workers, employment, etc)\n",
    "#     fig.add_subplot(3, 2, int(occ)+1, title = f'Occ: {int(occ)}')\n",
    "#     lgd = []\n",
    "#     for column in gtmp[1:]:\n",
    "#         plt.plot(gtmp[column])\n",
    "#         lgd.append(column)\n",
    "    \n",
    "# fig.suptitle(\"Economy Performance per Economy: Indicators over Time\", fontweight = 'bold')\n",
    "# fig.legend(list(lgd), bbox_to_anchor=(0.9, 0.3), ncols = 1, title_fontsize = \"6\", fontsize=\"8\")\n",
    "# fig.subplots_adjust(wspace=0.2, hspace = 0.75)\n",
    "# if final:\n",
    "#     plt.savefig('../output/occ_perf_base.jpg', dpi = 300)\n",
    "# else:\n",
    "#     plt.show()\n",
    "# plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "ltue_tot = sim_record_f.loc[:,['Sim','Time', 'Workers', 'Unemployment', 'LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "ltue_mean = ltue_tot.loc[:, ['Time', 'LTUE Rate']].groupby(['Time']).mean().reset_index()\n",
    "spl = splrep(ltue_mean['Time'], ltue_mean['LTUE Rate'], s=2)\n",
    "for g in np.unique(ltue_tot.Sim):\n",
    "    temp = ltue_tot[(ltue_tot['Sim'] == g)][['LTUE Rate', 'Time']]\n",
    "    ax1.plot(temp['Time'], temp['LTUE Rate'], alpha = 0.3)\n",
    "    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    #ax1.plot(temp['Time'], temp['UE Rate'])\n",
    "ax1.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "ax1.set_title(\"Non-behavioural\")\n",
    "fig.suptitle(\"LT Unemployment Rate\", fontweight = 'bold')\n",
    "\n",
    "\n",
    "ltue_tot = sim_record_t.loc[:,['Sim','Time', 'Workers', 'Unemployment','LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "ltue_mean = ltue_tot.loc[:, ['Time', 'LTUE Rate']].groupby(['Time']).mean().reset_index()\n",
    "spl = splrep(ltue_mean['Time'], ltue_mean['LTUE Rate'], s=2)\n",
    "for g in np.unique(ltue_tot.Sim):\n",
    "    temp = ltue_tot[(ltue_tot['Sim'] == g)][['LTUE Rate', 'Time']]\n",
    "    ax2.plot(temp['Time'], temp['LTUE Rate'], alpha = 0.2)\n",
    "    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    #ax2.plot(temp['Time'], temp['UE Rate'])\n",
    "ax2.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "ax2.set_title(\"Behavioural\")\n",
    "fig.suptitle(\"LT Unemployment Rate\", fontweight = 'bold')\n",
    "fig.tight_layout()\n",
    "\n",
    "if final:\n",
    "    plt.savefig('../output/ltuer_sim_comparison_behav.jpg', dpi = 300)\n",
    "else:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3bbd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "ltue_tot = sim_record_f.loc[:,['Sim','Time', 'Workers', 'Unemployment', 'LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "ltue_mean = ltue_tot.loc[:, ['Time', 'UE Rate']].groupby(['Time']).mean().reset_index()\n",
    "spl = splrep(ltue_mean['Time'], ltue_mean['UE Rate'], s=2)\n",
    "for g in np.unique(ltue_tot.Sim):\n",
    "    temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    ax1.plot(temp['Time'], temp['UE Rate'], alpha = 0.3)\n",
    "    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    #ax1.plot(temp['Time'], temp['UE Rate'])\n",
    "ax1.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "ax1.set_title(\"Non-behavioural\")\n",
    "fig.suptitle(\"Unemployment Rate\", fontweight = 'bold')\n",
    "\n",
    "\n",
    "ltue_tot = sim_record_t.loc[:,['Sim','Time', 'Workers', 'Unemployment','LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "ltue_mean = ltue_tot.loc[:, ['Time', 'UE Rate']].groupby(['Time']).mean().reset_index()\n",
    "spl = splrep(ltue_mean['Time'], ltue_mean['UE Rate'], s=2)\n",
    "for g in np.unique(ltue_tot.Sim):\n",
    "    temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    ax2.plot(temp['Time'], temp['UE Rate'], alpha = 0.2)\n",
    "    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    #ax2.plot(temp['Time'], temp['UE Rate'])\n",
    "ax2.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "ax2.set_title(\"Behavioural\")\n",
    "fig.suptitle(\"Unemployment Rate\", fontweight = 'bold')\n",
    "fig.tight_layout()\n",
    "\n",
    "if final:\n",
    "    plt.savefig('../output/ltuer_sim_comparison_behav.jpg', dpi = 300)\n",
    "else:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
