{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2137f9",
   "metadata": {},
   "source": [
    "# Micro- (and hopefully soon geo-) Founded Occupational Mobility Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee95600",
   "metadata": {},
   "source": [
    "*Setup from @rmaria del rio-chanona et al. 2021*\n",
    "*Code: @ebbamark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329d5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as random\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "from scipy.interpolate import splrep, BSpline\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "path = \"~/Documents/Documents - Nuff-Malham/GitHub/transition_abm/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2ff4c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390447b0",
   "metadata": {},
   "source": [
    "### Agents and Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f3e0f",
   "metadata": {},
   "source": [
    "One function and three classes are defined:\n",
    "- (Function) Utility/decision-making function used by workers when deciding which vacancies to apply to.\n",
    "- (Class) Worker: individual worker has state-specific attributes (whether or not employed, current or latest held occupation, time employed or unemployed, current or latest wage held, whether or not they have been hired in a particular time step) and character-specific attributes (occupational history, risk aversion score (not yet implemented) and an impatience score (not yet used)). Worker has one function which is to search and apply for a vacancy.\n",
    "- (Class) Occupation has an id, list of workers currently employed in that occupation, list of neighboring occupations based on transition adjacency matrix (imperfect solution), current and target demand for labour, list of applicants to open vacancies, and wage). Occupation has two internal functions (1) to separate workers and (2) to update all workers in an occupation after each time step.\n",
    "- (Class) Vacancy has an occupational id, list of applicants (duplicated above in occupation class...to fix), and a wage (duplicated above in occupation class...to fix). Vacancy has one internal function to hire an applicant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312cdd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining functions\n",
    "# Ranking utility/decision-making function\n",
    "def util(w_current, w_offered, skill_sim):\n",
    "    # No longer scale by impatience\n",
    "    # return 1/(1+(math.exp(-impatience_factor*((w_offered-(w_current*(1-skill_sim)))/10000))))\n",
    "    return 1/(1+(math.exp(-((w_offered - w_current)/10000))))\n",
    "\n",
    "# Simple quadratic for now in which a worker increase search effort for a period of 6 time steps (ie. months) \n",
    "# unemployed after which a worker begins to become discouraged. \n",
    "# This follows definition from the US BLS and Pew Research Centre\n",
    "def search_effort(t_unemp):\n",
    "    return round(20/((t_unemp-6)**2 + 1)) + 1\n",
    "\n",
    "## Defining classes\n",
    "# Potentially redundant use of IDs in the below classes...to check\n",
    "class worker:\n",
    "    def __init__(wrkr, occupation_id, employed, longterm_unemp, time_employed,\n",
    "                 time_unemployed, wage, hired, risk_av_score):\n",
    "        # State-specific attributes:\n",
    "        # Occupation id\n",
    "        wrkr.occupation_id = occupation_id\n",
    "        # Binary variable for whether employed or not\n",
    "        wrkr.employed = employed\n",
    "        # Binary variable for whether long-term unemployed\n",
    "        wrkr.longterm_unemp = longterm_unemp\n",
    "        # Number of time steps employed\n",
    "        wrkr.time_employed = time_employed\n",
    "        # Number of time steps unemployed (perhaps redundant with above)\n",
    "        # Used as criteria for impatience\n",
    "        wrkr.time_unemployed = time_unemployed\n",
    "        # Worker wage\n",
    "        # Could be used as additional criteria for impatience...\n",
    "        wrkr.wage = wage\n",
    "        # Whether the worker has been hired in this time step - reset to zero at the end of every time step\n",
    "        # Used as protective attribute in hiring process (ie. cannot be hired twice)\n",
    "        wrkr.hired = hired\n",
    "        \n",
    "        # Character-specific attributes:\n",
    "        # Employment history, list of occupations previously held\n",
    "        # NOT YET USED\n",
    "        #wrkr.emp_history = list_of_occs\n",
    "        # Identity score - to be defined...\n",
    "        # wrkr.identity = identity_score\n",
    "        # Risk aversion: Stefi suggested to use number of \n",
    "        # occupations previously held as proxy ie. len(emp_history)\n",
    "        # Currently takes a value 0-9 indicating at which index of utility ranked vacancies to start sampling/slicing\n",
    "        wrkr.risk_aversion = risk_av_score\n",
    "    \n",
    "    def search_and_apply(wrkr, net, vac_list, beh):\n",
    "        # A sample of relevant vacancies are found that are in neighboring occupations\n",
    "        # Will need to add a qualifier in case sample is greater than available relevant vacancies\n",
    "        # ^^ have added qualifier...bad form to reassign list?\n",
    "        rel_vacs = [vac for vac in vac_list if net[wrkr.occupation_id].list_of_neigh_bool[vac.occupation_id]]\n",
    "        #print(\"unemp workers: \", len(net[wrkr.occupation_id].list_of_unemployed))\n",
    "        #print(\"rel vacs: \", len(rel_vacs))\n",
    "        if beh:\n",
    "            rel_vacs = random.sample(rel_vacs, min(len(rel_vacs), 30))\n",
    "            # Sort found relevant vacancies by utility-function defined above and apply to amount dictated by impatience\n",
    "            for v in sorted(rel_vacs, key = lambda v: util(wrkr.wage, v.wage,net[wrkr.occupation_id].list_of_neigh_weights[v.occupation_id]), reverse = True)[slice(wrkr.risk_aversion, wrkr.risk_aversion + search_effort(wrkr.time_unemployed))]:\n",
    "                # Introduce randomness here...binomial?\n",
    "                v.applicants.append(wrkr)\n",
    "        else:\n",
    "            rel_vacs = random.sample(rel_vacs, min(len(rel_vacs), search_effort(wrkr.time_unemployed)))\n",
    "            for r in rel_vacs:\n",
    "                r.applicants.append(wrkr)\n",
    "            \n",
    "class occupation:\n",
    "    def __init__(occ, occupation_id, list_of_employed, list_of_unemployed, list_of_neigh_bool, \n",
    "                 list_of_neigh_weights, current_demand, \n",
    "                 target_demand, applicants, wage):\n",
    "        occ.occupation_id = occupation_id\n",
    "        occ.list_of_employed = list_of_employed\n",
    "        occ.list_of_unemployed = list_of_unemployed\n",
    "        occ.list_of_neigh_bool = list_of_neigh_bool\n",
    "        occ.list_of_neigh_weights = list_of_neigh_weights\n",
    "        occ.current_demand = current_demand\n",
    "        occ.target_demand = target_demand\n",
    "        occ.applicants = applicants\n",
    "        occ.wage = wage\n",
    "    \n",
    "    def separate_workers(occ, delta_u):\n",
    "        if(len(occ.list_of_employed) != 0):\n",
    "            sep_prob = delta_u + gamma * max(0, occ.current_demand - occ.target_demand)/(len(occ.list_of_employed) + 1)\n",
    "            #emp = [el for el in occ.list_of_workers if el.employed]\n",
    "            sep_counter = 0\n",
    "            #print(\"sep_prob: \",sep_prob)\n",
    "            #print(len(occ.list_of_employed))\n",
    "            w = np.random.binomial(len(occ.list_of_employed), sep_prob)\n",
    "            separated_workers = random.sample(occ.list_of_employed, w)\n",
    "            #print(separated_workers)\n",
    "            occ.list_of_unemployed = occ.list_of_unemployed + separated_workers\n",
    "            occ.list_of_employed = list(set(occ.list_of_employed) - set(separated_workers))\n",
    "#                 w.employed = False\n",
    "#                 w.longterm_unemp = False\n",
    "#                 w.time_employed = 0\n",
    "#                 w.time_unemployed = 0\n",
    "#                 sep_counter += 1\n",
    "    \n",
    "    def update_workers(occ):\n",
    "        for w in occ.list_of_unemployed:\n",
    "#             # Must update hired attribute of workers\n",
    "            w.hired = False\n",
    "#             if w.employed:\n",
    "#                 w.time_employed += 1\n",
    "#            if not(w.employed):\n",
    "            w.time_unemployed += 1\n",
    "            w.longterm_unemp = True if w.time_unemployed >= 7 else False\n",
    "                #don’t w.search_effort = search_effort(w.time_unemployed)\n",
    "                \n",
    "        \n",
    "class vac:\n",
    "    def __init__(v, occupation_id, applicants, wage):\n",
    "        v.occupation_id = occupation_id\n",
    "        v.applicants = applicants\n",
    "        v.wage = wage\n",
    "    def hire(v, net):\n",
    "        a = random.choice(v.applicants)\n",
    "        #assert(not(a.employed))\n",
    "        #assert(not(a.hired))\n",
    "        net[v.occupation_id].list_of_employed.append(net[a.occupation_id].list_of_unemployed.pop(net[a.occupation_id].list_of_unemployed.index(a)))\n",
    "        a.occupation_id = v.occupation_id\n",
    "        a.employed = True\n",
    "        a.longterm_unemp = False\n",
    "        a.time_employed = 0\n",
    "        a.time_unemployed = 0\n",
    "        a.wage = v.wage\n",
    "        #a.emp_history.append(v.occupation_id)\n",
    "        a.hired = True\n",
    "        # Reset?\n",
    "        # wrkr.risk_aversion = risk_av_score\n",
    "        # Reset?\n",
    "        # wrkr.impatience = impatience_score\n",
    "        v.applicants.clear()\n",
    "\n",
    "        \n",
    "def bus_cycle_demand(d_0, time, amp, period):\n",
    "    \"\"\"function that target demand of time t of sigmoid shock with parameters\n",
    "    Args:\n",
    "        d_0: vector of initial demand of occupation\n",
    "        d_final: (ignored)\n",
    "        amplitude: amplitude of business cycle\n",
    "        period: period for full business cycle\n",
    "    Returns\n",
    "        d_dagger(Array{Float64,2}): demand of occupation at time t\n",
    "    \"\"\"\n",
    "#     if t < t_shock:\n",
    "#         return d_0\n",
    "#    else:\n",
    "        # start cycle when shock starts\n",
    "        #t0 = t + t_shock\n",
    "    d_target =  d_0 * (1 - amp * np.sin((2*np.pi / period) * time))\n",
    "    return d_target\n",
    "\n",
    "#x1 = range(10)\n",
    "#plot(range(10), bus_cycle_demand(1000, range(10), 0.9, 15))\n",
    "#y1 = bus_cycle_demand(1000, range(10), 0.9, 15)\n",
    "# data = {'a': np.arange(10)}\n",
    "# data['b'] = bus_cycle_demand(1000, data['a'], 0.9, 15)\n",
    "# data['c'] = bus_cycle_demand(1000, data['a'], 0.5, 15)\n",
    "\n",
    "\n",
    "# plt.scatter('a', 'b', data=data)\n",
    "# plt.scatter('a', 'c', data=data)\n",
    "# plt.xlabel('entry a')\n",
    "# plt.ylabel('entry b')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346702b0",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388e404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make global decision as to which data to initialise network on. Current options are \"toy\" or \"USA\"\n",
    "#init = \"toy\"\n",
    "# behav = False\n",
    "shock = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70823b6",
   "metadata": {},
   "source": [
    "#### Toy Model\n",
    "Toy model constructed on 5 fake occupations with pre-determined employment, unemployment, vacancies, target demand, and wages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d87718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = 600\n",
    "# delta_u = 0.01\n",
    "# delta_v = 0.005\n",
    "# gamma_u = gamma_v = gamma = 0.01\n",
    "# # Import information about relevant files to employment/unemployment, target demand, vacancies, etc.\n",
    "\n",
    "# A = pd.read_csv(path+\"data/small_adj_full.csv\", delimiter=';', decimal=',', header=None)\n",
    "# employment = pd.read_csv(path+\"data/employed.csv\", header = None)\n",
    "# unemployment = pd.read_csv(path+\"data/unemployed.csv\", header = None)\n",
    "# vacancies = pd.read_csv(path+\"data/vacancies.csv\", header = None)\n",
    "# demand_target = employment + vacancies\n",
    "# wages = pd.DataFrame(np.round(np.random.normal(50000, 10000, 5)), columns = ['Wages'])\n",
    "# mod_data =  {\"A\": A, \"employment\": employment, \n",
    "#              'unemployment':unemployment, 'vacancies':vacancies, \n",
    "#              'demand_target': demand_target, 'wages': wages}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8849f",
   "metadata": {},
   "source": [
    "#### US Model\n",
    "Model constructed using 464 occupations from US Bureau of Labor Statistics Data and IPUMS.\n",
    "Data input from replicaiton code in dRC et al 2021: https://zenodo.org/records/4453162\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9fba2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# INITIAL MODEL CONDITIONS ########\n",
    "###################################\n",
    "#T = 500\n",
    "# del_u = 0.015\n",
    "# del_v = 0.009\n",
    "# gamma_u = gamma_v = gamma = 0.06\n",
    "\n",
    "# # Maria's params\n",
    "# del_u = 0.016 + 0.00000001 # adding zeros since useful for defining names\n",
    "# del_v = 0.012 + 0.00000001\n",
    "# gamma = 10*del_u\n",
    "\n",
    "A = pd.read_csv(path+\"dRC_Replication/data/occupational_mobility_network.csv\", header=None)\n",
    "employment = round(pd.read_csv(path+\"dRC_Replication/data/ipums_employment_2016.csv\", header = 0).iloc[:, [4]]/1000)\n",
    "# Crude approximation using avg unemployment rate of ~5% - should aim for occupation-specific unemployment rates\n",
    "unemployment = round(employment*(0.05/0.95))\n",
    "# Less crude approximation using avg vacancy rate - should still aim for occupation-specific vacancy rates\n",
    "vac_rate_base = pd.read_csv(path+\"dRC_Replication/data/vacancy_rateDec2000.csv\").iloc[:, 2].mean()/100\n",
    "vacancies = round(employment*vac_rate_base/(1-vac_rate_base))\n",
    "# Needs input data...\n",
    "demand_target = employment + vacancies\n",
    "wages = pd.read_csv(path+\"dRC_Replication/data/ipums_variables.csv\")[['median_earnings']]\n",
    "mod_data =  {\"A\": A, \"employment\": employment, \n",
    "             'unemployment':unemployment, 'vacancies':vacancies, \n",
    "             'demand_target': demand_target, 'wages': wages}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7aee7",
   "metadata": {},
   "source": [
    "### Initialise Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33329d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file init.py\n",
    "### Function and condition to initialise network\n",
    "\n",
    "def initialise(n_occ, employment, unemployment, vacancies, demand_target, A, wages):\n",
    "    \"\"\" Makes a list of occupations with initial conditions\n",
    "       Args:\n",
    "           n_occ: number of occupations initialised\n",
    "           employment: vector with employment of each occupation\n",
    "           unemployment: vector with unemployment of each occupation\n",
    "           vacancies: vector with vacancies of each occupation\n",
    "           demand_target: vector with (initial) target_demand for each occupation (never updated)\n",
    "           A: adjacency matrix of network (not including auto-transition probability)\n",
    "           wages: vector of wages of each occupation\n",
    "\n",
    "       Returns:\n",
    "            occupations: list of occupations with above attributes\n",
    "            vacancies: list of vacancies with occupation id, wage, and list of applicants\n",
    "       \"\"\"\n",
    "    occs = []\n",
    "    vac_list = []\n",
    "    ids = 0\n",
    "    for i in range(0, n_occ):\n",
    "        # appending relevant number of vacancies to economy-wide vacancy list\n",
    "        for v in range(round(vacancies.iat[i,0])):\n",
    "            vac_list.append(vac(i, [], wages.iat[i,0]))\n",
    "            \n",
    "        occ = occupation(i, [], [], A[i] > 0, A[i],\n",
    "                         (employment.iat[i,0] + vacancies.iat[i,0]), \n",
    "                         demand_target.iat[i,0], [], wages.iat[i,0])\n",
    "    \n",
    "        # creating the workers of occupation i and attaching to occupation\n",
    "        ## adding employed workers\n",
    "        for e in range(round(employment.iat[i,0])):\n",
    "            # Assume they have all at least 1 t.s. of employment\n",
    "            occ.list_of_employed.append(worker(occ.occupation_id, True, False, 1, 0, wages.iat[i,0], False, random.randint(0, 9)))\n",
    "            ## adding unemployed workers\n",
    "            # Could consider adding random initial unemployment durations...for now no one becomes longterm unemployed until 6 time steps in\n",
    "        for u in range(round(unemployment.iat[i,0])):\n",
    "            # Assigns time unemployed from absolute value of normal distribution....\n",
    "            occ.list_of_unemployed.append(worker(occ.occupation_id, False, False, 0, abs(int(np.random.normal(0, 2))), wages.iat[i,0], False,\n",
    "                 \n",
    "                                                      random.randint(0, 9)))\n",
    "        occs.append(occ)\n",
    "        ids += 1\n",
    "    return occs, vac_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "064bce83",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'occupation' object has no attribute 'employment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m net_temp, vacs \u001b[38;5;241m=\u001b[39m initialise(\u001b[38;5;28mlen\u001b[39m(mod_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m]), mod_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memployment\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m                             mod_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munemployment\u001b[39m\u001b[38;5;124m'\u001b[39m], mod_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvacancies\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      6\u001b[0m                             mod_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemand_target\u001b[39m\u001b[38;5;124m'\u001b[39m], mod_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m], mod_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwages\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mtype\u001b[39m(net_temp)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mnet_temp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memployment\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'occupation' object has no attribute 'employment'"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Testing Cell #####\n",
    "####################\n",
    "net_temp, vacs = initialise(len(mod_data['A']), mod_data['employment'],\n",
    "                            mod_data['unemployment'], mod_data['vacancies'], \n",
    "                            mod_data['demand_target'], mod_data['A'], mod_data['wages'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe09d1d",
   "metadata": {},
   "source": [
    "## Model Run\n",
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a596706",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Model Run ########\n",
    "####################\n",
    "def run_sim(behav_spec, data, time_steps, runs, d_u, d_v):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # Records variables of interest\n",
    "    record = pd.DataFrame(columns=['Sim', 'Time', 'Occupation_ID', 'Workers', 'Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand'])\n",
    "    print(record)\n",
    "    for run in range(runs):\n",
    "        #print(\"Running \", init, \" model.\")\n",
    "        # Initialise occupational mobility network\n",
    "        net_temp, vacs = initialise(len(data['A']), data['employment'], data['unemployment'], data['vacancies'], data['demand_target'], data['A'], data['wages'])\n",
    "        for t in range(time_steps):\n",
    "            print(\"Run: \", run, \"; TIME: \", t)\n",
    "            if t == 400 and shock:\n",
    "                print(\"initiatied shock!\")\n",
    "                net_temp[0].target_demand += 25\n",
    "                net_temp[1].target_demand += 50\n",
    "                net_temp[2].target_demand += 50\n",
    "                net_temp[3].target_demand += 50\n",
    "                net_temp[4].target_demand = 100\n",
    "\n",
    "            # Ensure number of workers in economy has not changed\n",
    "            #assert(sum(map(lambda x: len(x.list_of_workers), net_temp)) == employment.sum().item() + unemployment.sum().item())\n",
    "            for occ in net_temp:\n",
    "                # Ensure that separated workers have been reassigned appropriately \n",
    "                # (ie. that people move witihin the same occupation from employed to unemployed \n",
    "                # and that the total number of workers iwthin an occupation is (at this stage) \n",
    "                # the same as before separations\n",
    "#                 if t > 0:\n",
    "#                     temp = record.loc[(record['Sim'] == run) & (record['Occupation_ID'] == occ.occupation_id) & (record['Time'] == t-1)]\n",
    "#                     assert(temp.Employment.item() - sum(wrkr.employed for wrkr in occ.list_of_workers) ==\n",
    "#                            sum(not(wrkr.employed) for wrkr in occ.list_of_workers) - temp.Unemployment.item())\n",
    "#                     assert(len(occ.list_of_workers) == temp.Workers.item())\n",
    "\n",
    "                ### APPLICATIONS\n",
    "                # Questions to verify:\n",
    "                # - CANNOT be fired and apply in same time step ie. time_unemployed > 0\n",
    "                # - CAN be rejected and apply in the same time step - no protected attribute\n",
    "                #unemp = [el for el in occ.list_of_workers if not(el.employed) and el.time_unemployed > 0]\n",
    "                for u in occ.list_of_unemployed:\n",
    "                    u.search_and_apply(net_temp, vacs, behav_spec)\n",
    "                    \n",
    "                ### SEPARATIONS\n",
    "                occ.separate_workers(d_u)\n",
    "\n",
    "            ### HIRING\n",
    "            # Ordering of hiring randomised to ensure list order does not matter in filling vacancies...\n",
    "            # ....might be better to do this using an unordered set?\n",
    "            for v_open in sorted(vacs,key=lambda _: random.random()):\n",
    "                # Removes any applicants that have already been hired in another vacancy\n",
    "                v_open.applicants[:] = [app for app in v_open.applicants if not(app.hired)]\n",
    "                #print(\"apps: \", len(v_open.applicants))\n",
    "                if len(v_open.applicants) > 0:\n",
    "                #if len([app for app in v_open.applicants if not(app.hired)]) > 0:\n",
    "                    v_open.hire(net_temp)\n",
    "                    vacs.remove(v_open)\n",
    "                    assert(len(v_open.applicants) == 0)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            ### OPEN VACANCIES\n",
    "            # Update vacancies after all shifts have taken place\n",
    "            # Could consider making this a function of the class itself\n",
    "            for occ in net_temp:\n",
    "                # Update all workers\n",
    "                occ.update_workers()\n",
    "                #emp = sum(wrkr.employed for wrkr in occ.list_of_workers)\n",
    "                emp = len(occ.list_of_employed)\n",
    "                occ.current_demand = bus_cycle_demand(len([v_open for v_open in vacs if v_open.occupation_id == occ.occupation_id]) + emp, t, 0.06, 36)\n",
    "                vac_prob = d_v + ((1 - d_v) * (gamma * max(0, occ.target_demand - occ.current_demand))) / (emp + 1)\n",
    "                #print(\"vac prob:\", vac_prob)\n",
    "                for v in range(int(np.random.binomial(emp, vac_prob))):\n",
    "                    vacs.append(vac(occ.occupation_id, [], occ.wage))\n",
    "\n",
    "                ### UPDATE INDICATOR RECORD\n",
    "                # Record of indicators of interest (simulation number, occ, # workers, employed, unemployed, vacancies, long_term_unemployed)\n",
    "                record.loc[len(record)]= [run, \n",
    "                                          t,\n",
    "                                          occ.occupation_id,\n",
    "                                          len(occ.list_of_employed) + len(occ.list_of_unemployed),\n",
    "                                          len(occ.list_of_employed),\n",
    "                                          len(occ.list_of_unemployed),\n",
    "                                          len([v_open for v_open in vacs if v_open.occupation_id == occ.occupation_id]),\n",
    "                                          sum(wrkr.longterm_unemp for wrkr in occ.list_of_unemployed),\n",
    "                                          occ.target_demand]\n",
    "\n",
    "        print(\"Done after \", t + 1, \" time steps.\")\n",
    "    print(\"Done after \", run + 1, \" runs.\")\n",
    "    return(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5bff706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0152501, 0.015500100000000001]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_params\n",
    "# list of parameters to explore\n",
    "δ_u_list = [0.0150001 + i * 0.00025 for i in range(1,9)][0:2]\n",
    "δ_v_list = [0.009001 + i * 0.00025 for i in range(1,18)][0:2]\n",
    "amplitude_list = [0.06 + 0.0025*i for i in range(9)][0:2]\n",
    "τ_list = [i for i in range(2,8)][0:2]\n",
    "amplitude_list\n",
    "δ_u_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37dda9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T = 1000\n",
    "#del_u = 0.02\n",
    "#del_v = 0.015\n",
    "#gamma_u = gamma_v = gamma = 0.015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c43eedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_sim(behav_spec, data, time_steps, runs, d_u, d_v):\n",
    "#sim_record_f_all = run_sim(False, mod_data, T, 1, del_u, del_v)\n",
    "#sim_record_t_all = run_sim(False, mod_data, T, 1, del_u, del_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82e73f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c57571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results specifications (whether to save as final or not)\n",
    "final = False\n",
    "fullpdf = True\n",
    "\n",
    "T = 200\n",
    "# # Maria's params\n",
    "# del_u = 0.016 + 0.00000001 # adding zeros since useful for defining names\n",
    "# del_v = 0.012 + 0.00000001\n",
    "# gamma = 10*del_u\n",
    "\n",
    "\n",
    "#del_u = 0.012 + 0.00000001 # adding zeros since useful for defining names\n",
    "#del_v = 0.012 + 0.00000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc0533a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['δ_u: 0.005; δ_v: 0.01']\n",
      "Empty DataFrame\n",
      "Columns: [Sim, Time, Occupation_ID, Workers, Employment, Unemployment, Vacancies, LT Unemployed Persons, Target_Demand]\n",
      "Index: []\n",
      "Run:  0 ; TIME:  0\n",
      "Run:  0 ; TIME:  1\n",
      "Run:  0 ; TIME:  2\n",
      "Run:  0 ; TIME:  3\n",
      "Run:  0 ; TIME:  4\n",
      "Run:  0 ; TIME:  5\n",
      "Run:  0 ; TIME:  6\n",
      "Run:  0 ; TIME:  7\n",
      "Run:  0 ; TIME:  8\n",
      "Run:  0 ; TIME:  9\n",
      "Run:  0 ; TIME:  10\n",
      "Run:  0 ; TIME:  11\n",
      "Run:  0 ; TIME:  12\n",
      "Run:  0 ; TIME:  13\n",
      "Run:  0 ; TIME:  14\n",
      "Run:  0 ; TIME:  15\n",
      "Run:  0 ; TIME:  16\n",
      "Run:  0 ; TIME:  17\n",
      "Run:  0 ; TIME:  18\n",
      "Run:  0 ; TIME:  19\n",
      "Run:  0 ; TIME:  20\n",
      "Run:  0 ; TIME:  21\n",
      "Run:  0 ; TIME:  22\n",
      "Run:  0 ; TIME:  23\n",
      "Run:  0 ; TIME:  24\n",
      "Run:  0 ; TIME:  25\n",
      "Run:  0 ; TIME:  26\n",
      "Run:  0 ; TIME:  27\n",
      "Run:  0 ; TIME:  28\n",
      "Run:  0 ; TIME:  29\n",
      "Run:  0 ; TIME:  30\n",
      "Run:  0 ; TIME:  31\n",
      "Run:  0 ; TIME:  32\n",
      "Run:  0 ; TIME:  33\n",
      "Run:  0 ; TIME:  34\n",
      "Run:  0 ; TIME:  35\n",
      "Run:  0 ; TIME:  36\n",
      "Run:  0 ; TIME:  37\n",
      "Run:  0 ; TIME:  38\n",
      "Run:  0 ; TIME:  39\n",
      "Run:  0 ; TIME:  40\n",
      "Run:  0 ; TIME:  41\n",
      "Run:  0 ; TIME:  42\n",
      "Run:  0 ; TIME:  43\n",
      "Run:  0 ; TIME:  44\n",
      "Run:  0 ; TIME:  45\n",
      "Run:  0 ; TIME:  46\n",
      "Run:  0 ; TIME:  47\n",
      "Run:  0 ; TIME:  48\n",
      "Run:  0 ; TIME:  49\n",
      "Run:  0 ; TIME:  50\n",
      "Run:  0 ; TIME:  51\n",
      "Run:  0 ; TIME:  52\n",
      "Run:  0 ; TIME:  53\n",
      "Run:  0 ; TIME:  54\n",
      "Run:  0 ; TIME:  55\n",
      "Run:  0 ; TIME:  56\n",
      "Run:  0 ; TIME:  57\n",
      "Run:  0 ; TIME:  58\n",
      "Run:  0 ; TIME:  59\n",
      "Run:  0 ; TIME:  60\n",
      "Run:  0 ; TIME:  61\n",
      "Run:  0 ; TIME:  62\n",
      "Run:  0 ; TIME:  63\n",
      "Run:  0 ; TIME:  64\n",
      "Run:  0 ; TIME:  65\n",
      "Run:  0 ; TIME:  66\n",
      "Run:  0 ; TIME:  67\n",
      "Run:  0 ; TIME:  68\n",
      "Run:  0 ; TIME:  69\n",
      "Run:  0 ; TIME:  70\n",
      "Run:  0 ; TIME:  71\n",
      "Run:  0 ; TIME:  72\n",
      "Run:  0 ; TIME:  73\n",
      "Run:  0 ; TIME:  74\n",
      "Run:  0 ; TIME:  75\n",
      "Run:  0 ; TIME:  76\n",
      "Run:  0 ; TIME:  77\n",
      "Run:  0 ; TIME:  78\n",
      "Run:  0 ; TIME:  79\n",
      "Run:  0 ; TIME:  80\n",
      "Run:  0 ; TIME:  81\n",
      "Run:  0 ; TIME:  82\n",
      "Run:  0 ; TIME:  83\n",
      "Run:  0 ; TIME:  84\n",
      "Run:  0 ; TIME:  85\n",
      "Run:  0 ; TIME:  86\n",
      "Run:  0 ; TIME:  87\n",
      "Run:  0 ; TIME:  88\n",
      "Run:  0 ; TIME:  89\n",
      "Run:  0 ; TIME:  90\n",
      "Run:  0 ; TIME:  91\n",
      "Run:  0 ; TIME:  92\n",
      "Run:  0 ; TIME:  93\n",
      "Run:  0 ; TIME:  94\n",
      "Run:  0 ; TIME:  95\n",
      "Run:  0 ; TIME:  96\n",
      "Run:  0 ; TIME:  97\n",
      "Run:  0 ; TIME:  98\n",
      "Run:  0 ; TIME:  99\n",
      "Run:  0 ; TIME:  100\n",
      "Run:  0 ; TIME:  101\n",
      "Run:  0 ; TIME:  102\n",
      "Run:  0 ; TIME:  103\n",
      "Run:  0 ; TIME:  104\n",
      "Run:  0 ; TIME:  105\n",
      "Run:  0 ; TIME:  106\n",
      "Run:  0 ; TIME:  107\n",
      "Run:  0 ; TIME:  108\n",
      "Run:  0 ; TIME:  109\n",
      "Run:  0 ; TIME:  110\n",
      "Run:  0 ; TIME:  111\n",
      "Run:  0 ; TIME:  112\n",
      "Run:  0 ; TIME:  113\n",
      "Run:  0 ; TIME:  114\n",
      "Run:  0 ; TIME:  115\n",
      "Run:  0 ; TIME:  116\n",
      "Run:  0 ; TIME:  117\n",
      "Run:  0 ; TIME:  118\n",
      "Run:  0 ; TIME:  119\n",
      "Run:  0 ; TIME:  120\n",
      "Run:  0 ; TIME:  121\n",
      "Run:  0 ; TIME:  122\n",
      "Run:  0 ; TIME:  123\n",
      "Run:  0 ; TIME:  124\n",
      "Run:  0 ; TIME:  125\n",
      "Run:  0 ; TIME:  126\n",
      "Run:  0 ; TIME:  127\n",
      "Run:  0 ; TIME:  128\n",
      "Run:  0 ; TIME:  129\n",
      "Run:  0 ; TIME:  130\n",
      "Run:  0 ; TIME:  131\n",
      "Run:  0 ; TIME:  132\n",
      "Run:  0 ; TIME:  133\n",
      "Run:  0 ; TIME:  134\n",
      "Run:  0 ; TIME:  135\n",
      "Run:  0 ; TIME:  136\n",
      "Run:  0 ; TIME:  137\n",
      "Run:  0 ; TIME:  138\n",
      "Run:  0 ; TIME:  139\n",
      "Run:  0 ; TIME:  140\n",
      "Run:  0 ; TIME:  141\n",
      "Run:  0 ; TIME:  142\n",
      "Run:  0 ; TIME:  143\n",
      "Run:  0 ; TIME:  144\n",
      "Run:  0 ; TIME:  145\n",
      "Run:  0 ; TIME:  146\n",
      "Run:  0 ; TIME:  147\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39mdel_u\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mδ_u: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(del_u) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m; δ_v: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(del_v)])\n\u001b[0;32m----> 6\u001b[0m sim_record_f_all \u001b[38;5;241m=\u001b[39m \u001b[43mrun_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdel_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdel_v\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m sim_record_t_all \u001b[38;5;241m=\u001b[39m run_sim(\u001b[38;5;28;01mTrue\u001b[39;00m, mod_data, T, \u001b[38;5;241m1\u001b[39m, del_u, del_v)\n\u001b[1;32m      8\u001b[0m sim_record_t \u001b[38;5;241m=\u001b[39m sim_record_t_all\u001b[38;5;241m.\u001b[39mloc[(sim_record_t_all\u001b[38;5;241m.\u001b[39mTime \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m, in \u001b[0;36mrun_sim\u001b[0;34m(behav_spec, data, time_steps, runs, d_u, d_v)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m occ \u001b[38;5;129;01min\u001b[39;00m net_temp:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Ensure that separated workers have been reassigned appropriately \u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# (ie. that people move witihin the same occupation from employed to unemployed \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# - CAN be rejected and apply in the same time step - no protected attribute\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m#unemp = [el for el in occ.list_of_workers if not(el.employed) and el.time_unemployed > 0]\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m occ\u001b[38;5;241m.\u001b[39mlist_of_unemployed:\n\u001b[0;32m---> 43\u001b[0m         \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_and_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvacs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbehav_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m### SEPARATIONS\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     occ\u001b[38;5;241m.\u001b[39mseparate_workers(d_u)\n",
      "Cell \u001b[0;32mIn[2], line 53\u001b[0m, in \u001b[0;36mworker.search_and_apply\u001b[0;34m(wrkr, net, vac_list, beh)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_and_apply\u001b[39m(wrkr, net, vac_list, beh):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# A sample of relevant vacancies are found that are in neighboring occupations\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Will need to add a qualifier in case sample is greater than available relevant vacancies\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# ^^ have added qualifier...bad form to reassign list?\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     rel_vacs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mvac\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvac\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvac_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwrkr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moccupation_id\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_of_neigh_bool\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moccupation_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m#print(\"unemp workers: \", len(net[wrkr.occupation_id].list_of_unemployed))\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m#print(\"rel vacs: \", len(rel_vacs))\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m beh:\n",
      "Cell \u001b[0;32mIn[2], line 53\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_and_apply\u001b[39m(wrkr, net, vac_list, beh):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# A sample of relevant vacancies are found that are in neighboring occupations\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Will need to add a qualifier in case sample is greater than available relevant vacancies\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# ^^ have added qualifier...bad form to reassign list?\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     rel_vacs \u001b[38;5;241m=\u001b[39m [vac \u001b[38;5;28;01mfor\u001b[39;00m vac \u001b[38;5;129;01min\u001b[39;00m vac_list \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnet\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwrkr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moccupation_id\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_of_neigh_bool\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moccupation_id\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m#print(\"unemp workers: \", len(net[wrkr.occupation_id].list_of_unemployed))\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m#print(\"rel vacs: \", len(rel_vacs))\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m beh:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:967\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 967\u001b[0m     \u001b[43mcheck_deprecated_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:2656\u001b[0m, in \u001b[0;36mcheck_deprecated_indexers\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2645\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[1;32m   2648\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m   2650\u001b[0m         obj\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2651\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (obj\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2653\u001b[0m     )\n\u001b[0;32m-> 2656\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_deprecated_indexers\u001b[39m(key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2657\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Checks if the key is a deprecated indexer.\"\"\"\u001b[39;00m\n\u001b[1;32m   2658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2659\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mset\u001b[39m)\n\u001b[1;32m   2660\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m   2661\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mset\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   2662\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with PdfPages('multipage_us_k.pdf') as pdf:\n",
    "    for del_u in [0.005]:#δ_u_list:\n",
    "        for del_v in [0.01]: #δ_v_list:\n",
    "                gamma = 10*del_u\n",
    "                print([\"δ_u: \" + str(del_u) + \"; δ_v: \" + str(del_v)])\n",
    "                sim_record_f_all = run_sim(False, mod_data, T, 1, del_u, del_v)\n",
    "                sim_record_t_all = run_sim(True, mod_data, T, 1, del_u, del_v)\n",
    "                sim_record_t = sim_record_t_all.loc[(sim_record_t_all.Time > 0)]\n",
    "                sim_record_f = sim_record_f_all.loc[(sim_record_f_all.Time > 0)]\n",
    "                record1_f = sim_record_f.loc[(sim_record_f.Sim == 0)]\n",
    "                record1_t = sim_record_t.loc[(sim_record_t.Sim == 0)]\n",
    "\n",
    "                txt = [\"δ_u: \" + str(del_u) + \"; δ_v: \" + str(del_v)]\n",
    "                ue_vac_f = record1_f.loc[:,['Time', 'Workers', 'Unemployment', 'Vacancies', 'Target_Demand']].groupby(['Time']).sum().reset_index()\n",
    "                ue_vac_f['UE Rate'] = ue_vac_f['Unemployment'] / ue_vac_f['Workers']\n",
    "                ue_vac_f['Vac Rate'] = ue_vac_f['Vacancies'] / ue_vac_f['Target_Demand']\n",
    "                ue_vac_f = ue_vac_f.loc[(ue_vac_f.Time > 300) & (ue_vac_f.Time < 327)]\n",
    "\n",
    "                ue_vac_t = record1_t.loc[:,['Time', 'Workers', 'Unemployment', 'Vacancies', 'Target_Demand']].groupby(['Time']).sum().reset_index()\n",
    "                ue_vac_t['UE Rate'] = ue_vac_t['Unemployment'] / ue_vac_t['Workers']\n",
    "                ue_vac_t['Vac Rate'] = ue_vac_t['Vacancies'] / ue_vac_t['Target_Demand']\n",
    "                ue_vac_t = ue_vac_t.loc[(ue_vac_t.Time > 300) & (ue_vac_t.Time < 327)]\n",
    "\n",
    "\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "                ax1.plot(ue_vac_f['UE Rate'], ue_vac_f['Vac Rate'])\n",
    "                ax1.scatter(ue_vac_f['UE Rate'], ue_vac_f['Vac Rate'], c=ue_vac_f['Time'], s=100, lw=0)\n",
    "                ax1.set_title(\"Non-behavioural\")\n",
    "                ax1.set_xlabel(\"UE Rate\")\n",
    "                ax1.set_ylabel(\"Vacancy Rate\")\n",
    "\n",
    "                ax2.plot(ue_vac_t['UE Rate'], ue_vac_t['Vac Rate'])\n",
    "                ax2.set_title(\"Behavioural\")\n",
    "                ax2.scatter(ue_vac_t['UE Rate'], ue_vac_t['Vac Rate'], c=ue_vac_t['Time'], s=100, lw=0)\n",
    "                ax2.set_xlabel(\"UE Rate\")\n",
    "                ax2.set_ylabel(\"Vacancy Rate\")\n",
    "\n",
    "                fig.text(0.05,0.95,txt, transform=fig.transFigure, size=18)\n",
    "                fig.suptitle(\"Beveridge Curve\", fontweight = 'bold')\n",
    "                fig.tight_layout()\n",
    "\n",
    "\n",
    "                if final:\n",
    "                    plt.savefig('../output/overall_economy_comparison_behav.jpg', dpi = 300)\n",
    "                elif fullpdf:\n",
    "                    pdf.savefig()\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "                totals = record1_f.loc[:,['Time', 'Workers','Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']].groupby(['Time']).sum()\n",
    "                lgd = []\n",
    "                for column in totals[1:]:\n",
    "                    ax1.plot(totals[column])\n",
    "                    lgd.append(column)\n",
    "                ax1.set_title(\"Non-behavioural\")\n",
    "\n",
    "                totals = record1_t.loc[:,['Time', 'Workers','Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']].groupby(['Time']).sum()\n",
    "                for column in totals[1:]:\n",
    "                    ax2.plot(totals[column])\n",
    "                ax2.set_title('Behavioural')\n",
    "\n",
    "                fig.suptitle(\"Overall Economy Performance: Indicators over Time\", fontweight = 'bold')\n",
    "                plt.legend(list(lgd), loc=\"center\", ncol=1, fontsize = 8)\n",
    "                fig.tight_layout()\n",
    "\n",
    "                if final:\n",
    "                    plt.savefig('../output/overall_economy_comparison_behav.jpg', dpi = 300)\n",
    "                elif fullpdf:\n",
    "                    pdf.savefig()\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "                #### Occupations: Employment, Unemployment, Worker, Vacancy, and Longterm Unemployed Levels\n",
    "                # # Overall indicators per occupation\n",
    "                # ids = np.unique(record1_t.Occupation_ID)\n",
    "                # fig = plt.figure(constrained_layout = False)\n",
    "\n",
    "                # occ_totals = record1_t.loc[:,['Time', 'Occupation_ID', 'Workers','Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']]\n",
    "                # for occ in ids:\n",
    "                #     gtmp = occ_totals[(occ_totals['Occupation_ID'] == occ)].loc[:, ['Time', 'Workers', 'Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']].groupby(['Time']).sum()\n",
    "                #     # Indicators (workers, employment, etc)\n",
    "                #     fig.add_subplot(3, 2, int(occ)+1, title = f'Occ: {int(occ)}')\n",
    "                #     lgd = []\n",
    "                #     for column in gtmp[1:]:\n",
    "                #         plt.plot(gtmp[column])\n",
    "                #         lgd.append(column)\n",
    "\n",
    "                # fig.suptitle(\"Economy Performance per Economy: Indicators over Time\", fontweight = 'bold')\n",
    "                # fig.legend(list(lgd), bbox_to_anchor=(0.9, 0.3), ncols = 1, title_fontsize = \"6\", fontsize=\"8\")\n",
    "                # fig.subplots_adjust(wspace=0.2, hspace = 0.75)\n",
    "                # if final:\n",
    "                #     plt.savefig('../output/occ_perf_base.jpg', dpi = 300)\n",
    "                # else:\n",
    "                #     plt.show()\n",
    "                # plt.close(fig)\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "                ltue_tot = sim_record_f.loc[:,['Sim','Time', 'Workers', 'Unemployment', 'LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "                ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "                ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "                ltue_mean = ltue_tot.loc[:, ['Time', 'LTUE Rate']].groupby(['Time']).mean().reset_index()\n",
    "                spl = splrep(ltue_mean['Time'], ltue_mean['LTUE Rate'], s=2)\n",
    "                for g in np.unique(ltue_tot.Sim):\n",
    "                    temp = ltue_tot[(ltue_tot['Sim'] == g)][['LTUE Rate', 'Time']]\n",
    "                    ax1.plot(temp['Time'], temp['LTUE Rate'], alpha = 0.3)\n",
    "                    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "                    #ax1.plot(temp['Time'], temp['UE Rate'])\n",
    "                ax1.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "                ax1.set_title(\"Non-behavioural\")\n",
    "                fig.suptitle(\"LT Unemployment Rate\", fontweight = 'bold')\n",
    "\n",
    "\n",
    "                ltue_tot = sim_record_t.loc[:,['Sim','Time', 'Workers', 'Unemployment','LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "                ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "                ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "                ltue_mean = ltue_tot.loc[:, ['Time', 'LTUE Rate']].groupby(['Time']).mean().reset_index()\n",
    "                spl = splrep(ltue_mean['Time'], ltue_mean['LTUE Rate'], s=2)\n",
    "                for g in np.unique(ltue_tot.Sim):\n",
    "                    temp = ltue_tot[(ltue_tot['Sim'] == g)][['LTUE Rate', 'Time']]\n",
    "                    ax2.plot(temp['Time'], temp['LTUE Rate'], alpha = 0.2)\n",
    "                    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "                    #ax2.plot(temp['Time'], temp['UE Rate'])\n",
    "                ax2.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "                ax2.set_title(\"Behavioural\")\n",
    "                fig.suptitle(\"LT Unemployment Rate\", fontweight = 'bold')\n",
    "                fig.tight_layout()\n",
    "\n",
    "                if final:\n",
    "                    plt.savefig('../output/ltuer_sim_comparison_behav.jpg', dpi = 300)\n",
    "                elif fullpdf:\n",
    "                    pdf.savefig()\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "                ltue_tot = sim_record_f.loc[:,['Sim','Time', 'Workers', 'Unemployment', 'LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "                ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "                ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "                ltue_mean = ltue_tot.loc[:, ['Time', 'UE Rate']].groupby(['Time']).mean().reset_index()\n",
    "                spl = splrep(ltue_mean['Time'], ltue_mean['UE Rate'], s=2)\n",
    "                for g in np.unique(ltue_tot.Sim):\n",
    "                    temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "                    ax1.plot(temp['Time'], temp['UE Rate'], alpha = 0.3)\n",
    "                    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "                    #ax1.plot(temp['Time'], temp['UE Rate'])\n",
    "                ax1.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "                ax1.set_title(\"Non-behavioural\")\n",
    "                fig.suptitle(\"Unemployment Rate\", fontweight = 'bold')\n",
    "\n",
    "\n",
    "                ltue_tot = sim_record_t.loc[:,['Sim','Time', 'Workers', 'Unemployment','LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "                ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "                ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "                ltue_mean = ltue_tot.loc[:, ['Time', 'UE Rate']].groupby(['Time']).mean().reset_index()\n",
    "                spl = splrep(ltue_mean['Time'], ltue_mean['UE Rate'], s=2)\n",
    "                for g in np.unique(ltue_tot.Sim):\n",
    "                    temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "                    ax2.plot(temp['Time'], temp['UE Rate'], alpha = 0.2)\n",
    "                    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "                    #ax2.plot(temp['Time'], temp['UE Rate'])\n",
    "                ax2.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "                ax2.set_title(\"Behavioural\")\n",
    "                fig.suptitle(\"Unemployment Rate\", fontweight = 'bold')\n",
    "                fig.tight_layout()\n",
    "\n",
    "                if final:\n",
    "                    plt.savefig('../output/ltuer_sim_comparison_behav.jpg', dpi = 300)\n",
    "                elif fullpdf:\n",
    "                    pdf.savefig()\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results specifications (whether to save as final or not)\n",
    "final = False\n",
    "# sim_record_t = sim_record_t_all.loc[(sim_record_t_all.Time > 0)]\n",
    "# sim_record_f = sim_record_f_all.loc[(sim_record_f_all.Time > 0)]\n",
    "# record1_t = sim_record_t.loc[(sim_record_t.Sim == 0)]\n",
    "# record1_f = sim_record_f.loc[(sim_record_f.Sim == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e73633",
   "metadata": {},
   "source": [
    "#### Beveridge curve validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15caea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_vac_f = record1_f.loc[:,['Time', 'Workers', 'Unemployment', 'Vacancies', 'Target_Demand']].groupby(['Time']).sum().reset_index()\n",
    "ue_vac_f['UE Rate'] = ue_vac_f['Unemployment'] / ue_vac_f['Workers']\n",
    "ue_vac_f['Vac Rate'] = ue_vac_f['Vacancies'] / ue_vac_f['Target_Demand']\n",
    "ue_vac_f = ue_vac_f.loc[(ue_vac_f.Time > 300) & (ue_vac_f.Time < 327)]\n",
    "\n",
    "ue_vac_t = record1_t.loc[:,['Time', 'Workers', 'Unemployment', 'Vacancies', 'Target_Demand']].groupby(['Time']).sum().reset_index()\n",
    "ue_vac_t['UE Rate'] = ue_vac_t['Unemployment'] / ue_vac_t['Workers']\n",
    "ue_vac_t['Vac Rate'] = ue_vac_t['Vacancies'] / ue_vac_t['Target_Demand']\n",
    "ue_vac_t = ue_vac_t.loc[(ue_vac_t.Time > 300) & (ue_vac_t.Time < 327)]\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "ax1.plot(ue_vac_f['UE Rate'], ue_vac_f['Vac Rate'])\n",
    "ax1.scatter(ue_vac_f['UE Rate'], ue_vac_f['Vac Rate'], c=ue_vac_f['Time'], s=100, lw=0)\n",
    "ax1.set_title(\"Non-behavioural\")\n",
    "ax1.set_xlabel(\"UE Rate\")\n",
    "ax1.set_ylabel(\"Vacancy Rate\")\n",
    "\n",
    "ax2.plot(ue_vac_t['UE Rate'], ue_vac_t['Vac Rate'])\n",
    "ax2.set_title(\"Behavioural\")\n",
    "ax2.scatter(ue_vac_t['UE Rate'], ue_vac_t['Vac Rate'], c=ue_vac_t['Time'], s=100, lw=0)\n",
    "ax2.set_xlabel(\"UE Rate\")\n",
    "ax2.set_ylabel(\"Vacancy Rate\")\n",
    "\n",
    "    \n",
    "fig.suptitle(\"USA Model Beveridge Curve\", fontweight = 'bold')\n",
    "fig.tight_layout()\n",
    "\n",
    "# if final:\n",
    "#     plt.savefig('../output/overall_economy_comparison_behav.jpg', dpi = 300)\n",
    "# else:\n",
    "#     plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616eee6",
   "metadata": {},
   "source": [
    "#### Overall Economy: Employment, Unemployment, Worker, Vacancy, and Longterm Employed Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768368ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "totals = record1_f.loc[:,['Time', 'Workers','Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']].groupby(['Time']).sum()\n",
    "lgd = []\n",
    "for column in totals[1:]:\n",
    "    ax1.plot(totals[column])\n",
    "    lgd.append(column)\n",
    "ax1.set_title(\"Non-behavioural\")\n",
    "    \n",
    "totals = record1_t.loc[:,['Time', 'Workers','Employment', 'Unemployment', 'Vacancies', 'LT Unemployed Persons', 'Target_Demand']].groupby(['Time']).sum()\n",
    "for column in totals[1:]:\n",
    "    ax2.plot(totals[column])\n",
    "ax2.set_title('Behavioural')\n",
    "\n",
    "fig.suptitle(\"Overall Economy Performance: Indicators over Time\", fontweight = 'bold')\n",
    "plt.legend(list(lgd), loc=\"center\", ncol=1, fontsize = 8)\n",
    "fig.tight_layout()\n",
    "\n",
    "if final:\n",
    "    plt.savefig('../output/overall_economy_comparison_behav.jpg', dpi = 300)\n",
    "else:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fb0f4",
   "metadata": {},
   "source": [
    "#### Long-term unemployment rate and levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaae90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "# colors = colors = ['b','g','r','y','m']\n",
    "\n",
    "# sim_record_f['UE Rate'] = sim_record_f['Unemployment'] / sim_record_f['Workers']\n",
    "# for o in np.unique(sim_record_f.Occupation_ID):\n",
    "#     temp = sim_record_f[(sim_record_f['Occupation_ID'] == o)][['UE Rate', 'Time', 'Sim']]\n",
    "#     temp_mean = temp.loc[:, ['Time', 'UE Rate']].groupby(['Time']).mean().reset_index()\n",
    "#     spl = splrep(temp_mean['Time'], temp_mean['UE Rate'], s=2)\n",
    "#     for g in np.unique(temp.Sim):\n",
    "#         ax1.plot(temp[(temp['Sim'] == g)]['Time'], temp[(temp['Sim'] == g)]['UE Rate'], alpha = 0.05, color = colors[o])\n",
    "#     ax1.plot(temp_mean['Time'], BSpline(*spl)(temp_mean['Time']), '-', color = colors[o])\n",
    "# ax1.set_title(\"Non-behavioural\")\n",
    "# fig.suptitle(\"Unemployment Rate\", fontweight = 'bold')\n",
    "\n",
    "# sim_record_t['UE Rate'] = sim_record_t['Unemployment'] / sim_record_t['Workers']\n",
    "# for o in np.unique(sim_record_t.Occupation_ID):\n",
    "#     temp = sim_record_t[(sim_record_t['Occupation_ID'] == o)][['UE Rate', 'Time', 'Sim']]\n",
    "#     temp_mean = temp.loc[:, ['Time', 'UE Rate']].groupby(['Time']).mean().reset_index()\n",
    "#     spl = splrep(temp_mean['Time'], temp_mean['UE Rate'], s=3)\n",
    "#     for g in np.unique(temp.Sim):\n",
    "#         ax2.plot(temp[(temp['Sim'] == g)]['Time'], temp[(temp['Sim'] == g)]['UE Rate'], alpha = 0.05, color = colors[o])\n",
    "#     ax2.plot(temp_mean['Time'], BSpline(*spl)(temp_mean['Time']), '-', color = colors[o])\n",
    "# ax2.set_title(\"Behavioural\")\n",
    "# fig.suptitle(\"Unemployment Rate by Occupation\", fontweight = 'bold')\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f4e26",
   "metadata": {},
   "source": [
    "#### Occupations: Employment, Unemployment, Worker, Vacancy, and Longterm Unemployed Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55729cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "ltue_tot = sim_record_f.loc[:,['Sim','Time', 'Workers', 'Unemployment', 'LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "ltue_mean = ltue_tot.loc[:, ['Time', 'LTUE Rate']].groupby(['Time']).mean().reset_index()\n",
    "spl = splrep(ltue_mean['Time'], ltue_mean['LTUE Rate'], s=2)\n",
    "for g in np.unique(ltue_tot.Sim):\n",
    "    temp = ltue_tot[(ltue_tot['Sim'] == g)][['LTUE Rate', 'Time']]\n",
    "    ax1.plot(temp['Time'], temp['LTUE Rate'], alpha = 0.3)\n",
    "    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    #ax1.plot(temp['Time'], temp['UE Rate'])\n",
    "ax1.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "ax1.set_title(\"Non-behavioural\")\n",
    "fig.suptitle(\"LT Unemployment Rate\", fontweight = 'bold')\n",
    "\n",
    "\n",
    "ltue_tot = sim_record_t.loc[:,['Sim','Time', 'Workers', 'Unemployment','LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "ltue_mean = ltue_tot.loc[:, ['Time', 'LTUE Rate']].groupby(['Time']).mean().reset_index()\n",
    "spl = splrep(ltue_mean['Time'], ltue_mean['LTUE Rate'], s=2)\n",
    "for g in np.unique(ltue_tot.Sim):\n",
    "    temp = ltue_tot[(ltue_tot['Sim'] == g)][['LTUE Rate', 'Time']]\n",
    "    ax2.plot(temp['Time'], temp['LTUE Rate'], alpha = 0.2)\n",
    "    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    #ax2.plot(temp['Time'], temp['UE Rate'])\n",
    "ax2.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "ax2.set_title(\"Behavioural\")\n",
    "fig.suptitle(\"LT Unemployment Rate\", fontweight = 'bold')\n",
    "fig.tight_layout()\n",
    "\n",
    "if final:\n",
    "    plt.savefig('../output/ltuer_sim_comparison_behav.jpg', dpi = 300)\n",
    "else:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "ltue_tot = sim_record_f.loc[:,['Sim','Time', 'Workers', 'Unemployment', 'LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "ltue_mean = ltue_tot.loc[:, ['Time', 'UE Rate']].groupby(['Time']).mean().reset_index()\n",
    "spl = splrep(ltue_mean['Time'], ltue_mean['UE Rate'], s=2)\n",
    "for g in np.unique(ltue_tot.Sim):\n",
    "    temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    ax1.plot(temp['Time'], temp['UE Rate'], alpha = 0.3)\n",
    "    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    #ax1.plot(temp['Time'], temp['UE Rate'])\n",
    "ax1.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "ax1.set_title(\"Non-behavioural\")\n",
    "fig.suptitle(\"Unemployment Rate\", fontweight = 'bold')\n",
    "\n",
    "\n",
    "ltue_tot = sim_record_t.loc[:,['Sim','Time', 'Workers', 'Unemployment','LT Unemployed Persons']].groupby(['Time', 'Sim']).sum().reset_index()\n",
    "ltue_tot['UE Rate'] = ltue_tot['Unemployment'] / ltue_tot['Workers']\n",
    "ltue_tot['LTUE Rate'] = ltue_tot['LT Unemployed Persons'] / ltue_tot['Workers']\n",
    "ltue_mean = ltue_tot.loc[:, ['Time', 'UE Rate']].groupby(['Time']).mean().reset_index()\n",
    "spl = splrep(ltue_mean['Time'], ltue_mean['UE Rate'], s=2)\n",
    "for g in np.unique(ltue_tot.Sim):\n",
    "    temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    ax2.plot(temp['Time'], temp['UE Rate'], alpha = 0.2)\n",
    "    #temp = ltue_tot[(ltue_tot['Sim'] == g)][['UE Rate', 'Time']]\n",
    "    #ax2.plot(temp['Time'], temp['UE Rate'])\n",
    "ax2.plot(ltue_mean['Time'], BSpline(*spl)(ltue_mean['Time']), '-', label='s=0',  color = 'black')\n",
    "ax2.set_title(\"Behavioural\")\n",
    "fig.suptitle(\"Unemployment Rate\", fontweight = 'bold')\n",
    "fig.tight_layout()\n",
    "\n",
    "if final:\n",
    "    plt.savefig('../output/ltuer_sim_comparison_behav.jpg', dpi = 300)\n",
    "else:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
