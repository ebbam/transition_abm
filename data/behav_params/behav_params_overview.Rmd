---
title: "Data Scoping: Job Search Behaviour"
author: "Ebba Mark"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    keep_tex: true
    latex_engine: xelatex
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

# Overview {.tabset}

The following document summarises current progress on identifying data
sources to inform the job search behaviour in our labour market ABM.

**Goals:**

1.  Identify parameters relevant to agent search behaviour in the ABM.

2.  Assess data quality for deriving empirical estimates of these
    parameters.

We have narrowed the list of behavioural adjustments to the following:\
- **Duration-dependent search effort**\
- **Reservation Wage Adjustment Rates**\
- **Cyclical On-the-Job Search**\
- **Risk Aversion**: For now this is randomised to ensure variation in
vacancy targeting by similar workers. This is not yet supported by data.

<!-- - *Dynamic selection* (heterogeneity of job seekers - fitness & skills match for the current labour market) -->

<!-- - *Duration dependence* (job-finding probability decreases over time spent unemployed indendent of job-seeker characteristics) -->

<!-- - *Search effort* (individuals can exert greater search effort to counteract duration dependence - generally exhibits a countercyclical behaviour - job search effort increases as the economy recedes) -->

<!-- **Current idea:** If we view *dynamic selection* simply as worker heterogeneity, *duration dependence* as an endogenous process of skill deterioration or signal to employers (up to a certain point), and *search effort* as responsive to labour market conditions, we will have quasi-independent elements in the job-finding probability of workers in the model! -->

```{r setup, include=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE)
library(tidyverse)
library(here)
library(janitor)
library(gridExtra)
library(MASS)
library(kableExtra)
library(knitr)
library(pdftools)
library(haven)
library(lubridate)
library(vctrs)
library(gets)
library(patchwork)
library(modelsummary)
library(conflicted)
source(here('code/formatting/plot_dicts.R'))
conflict_prefer_all("dplyr", quiet = TRUE)
conflicts_prefer(patchwork::area)

```

## **Relevant Analyses** {.tabset}

**Data we have decided to keep:**

1.  Current Population Survey 2018 & 2022: Information on applications
    sent by unemployment duration.             
    
2.  Mukoyama et al. data on the intensive margin of unemployed search
    effort (in minutes searched) over the business cycle. We have chosen
    to include this as a validation exercise of our application effort
    imposition.               

3.  [Eeckhout et al. 2019 Unemployment
    Cycles](https://www.aeaweb.org/articles?id=10.1257/mac.20180105): We
    derive the sensitivity of employed job seekers to the business cycle
    from the employment-to-employment transitions data as used in
    Eeckhout et al. Due to unreliable component parts of the Eeckhout
    analysis, we decided to abandon using their estimated parameters
    (search intensity for employed workers).               
    
4.   Displaced Worker Supplement: As part of the Current Population Survey, the US Census Bureau conducts an annual Displaced Worker Supplement in which workers who have lost their job in the last three years are asked additional questions about their unemployment experiences and (if re-employed) their re-employment conditions. From this we draw a reservation wage adjustment rate as a function of unemployment duration.                  

5.   [**Mueller et al. 2021: Job Seekers' Perceptions and Employment
    Prospects: Heterogeneity, Duration Dependence and
    Bias**](https://www.aeaweb.org/articles?id=10.1257/aer.20190808)           

**Additional analyses that we have decided to exclude as data inputs due
to lack of relevance or poor data quality are in the "Discarded
Analyses" tab.**

### Applications Sent {.tabset}

#### Current Population Survey - 2018 & 2020 Supplement

This 2020 ["Beyond the Numbers"
issue](https://www.bls.gov/opub/btn/volume-9/how-do-jobseekers-search-for-jobs.htm#_edn5)
distills insights from a 2018 Supplement to the Current Population
Survey. The below plots show the highlights relevant to our
decision-making on the job search process. In nearly all cases, the
results are "binned" into intervals (ie. number of people sending 81 or
more applications or unemployment duration of between 5 and 14 weeks)
which means that any line plots (or linear interpretation of the bar
graph) should be done carefully. Preliminary results using the raw data
are found in the next section.

-   Figure 1: Shows the proportion of all individuals sending x amount
    of applications receiving y amount of interviews. The plot indicates
    a "consistent" return to sending more applications, although as
    demonstrated in Figure 3, the number of interviews received does not
    necessarily equate to receiving a job offer.

-   Figure 2: Demonstrates the number of applications sent (red),
    interviews received (green), average interview:applicaiton ratio
    (blue), and probability of receiving a job offer (purple) by
    individuals in each category of unemployment duration. There is some
    indication (although, again, interpretation is difficult without the
    raw data) that both effort and success seems to increase and then
    decline with time spent in unemployment, apart from success as
    measured by receiving a job offer which seems to consistently
    decline with time spent in unemployment.

-   Figure 3: Percentage of jobseekers receiving an offer seems to
    increase as a function of the number of applications sent, until a
    certain point.

```{r, echo = FALSE, include = TRUE, cache = TRUE}
source(here('data/ATUS/cps_2018_supplement.R'))

names(file_tables) <- table_titles

temp <- file_tables[[1]]

names(temp) <- temp[1,]
temp <- temp[-1,] %>%
  clean_names %>%
  select(-c(na, total)) %>%
  slice(-n()) %>%
  mutate(across(starts_with("x"), as.numeric))

# Gather the data into long format for ggplot
df_long <- temp %>%
  gather(key = interviews, value = "Proportion", -applications) %>%
  mutate(Proportion = Proportion/100,
         interviews = gsub("x", "", gsub("_", " ", interviews)))

# Create the heatmap plot using ggplot
p1 <- ggplot(df_long, aes(y = interviews, x = applications, fill = Proportion)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +  # Customize color gradient
  labs(title = paste0("1. ", sub(", 2018", "", sub("^Table\\s+\\d+\\.\\s*", "", names(file_tables[1])))), x = "Number of Applications Sent", y = "Interviews Received",
       caption = "Shading indicates the proportion of ppl sending X applications receiving Y interviews.") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
          plot.title = element_text(size = 8)) +
  common_theme



job_finding_rate <- file_tables[[5]] %>%
  slice(-n()) %>%
  clean_names()

search_effort <- file_tables[[2]] %>%
  slice(-n()) %>%
  clean_names() %>%
  left_join(., job_finding_rate, by = "duration_of_unemployment") %>%
  mutate(duration = row_number(),
         across(2:5, as.numeric),
         probability_of_receiving_job_offer = probability_of_receiving_job_offer/100) %>%
  pivot_longer(!c(duration_of_unemployment, duration)) %>%
  mutate(name = factor(name, levels = c("average_number_of_applications",
                                        "average_number_of_interviews",
                                        "average_interview_to_application_ratio",
                                        "probability_of_receiving_job_offer")))

rename_fun <- function(x){
  return(str_to_title(gsub("_", " ", x)))
}

p2 <- ggplot() +
  geom_line(data = filter(search_effort, duration != 1),
            aes(x = duration, y = value, colour = name)) +
  scale_x_continuous(breaks =2:5,
    labels = c("Less than 5 weeks", "5 to 14 weeks", "15 to 26 weeks", "27 weeks and over")) +
  labs(title = paste0("2. ", sub(", 2018", "", sub("^Table\\s+\\d+\\.\\s*", "", names(file_tables[2])))), x = "Unemployment Duration", y = "") +
  facet_wrap(~name, scales = "free_y", ncol = 1, labeller = labeller(name = rename_fun)) +
    theme(axis.text.x=element_text(angle=90),
          legend.position = "none",
          legend.title = element_blank(),
          plot.title = element_text(size = 8)) +
  common_theme


job_offer_rate_apps <- file_tables[[3]] %>%
  slice(-n()) %>%
  clean_names() %>%
  mutate(applications = factor(applications, levels = c("All jobseekers", "0", "1 to 10", "11 to 20", "21 to 80", "81 or more")),
         probability_of_receiving_job_offer = as.numeric(probability_of_receiving_job_offer))

p3 <- ggplot() +
  geom_bar(data = filter(job_offer_rate_apps, applications != "All jobseekers"),
            aes(x = applications, y = probability_of_receiving_job_offer), fill = "coral2", stat = "identity", width = 0.5) +
  labs(title = paste0("3. ", sub(", 2018", "", sub("^Table\\s+\\d+\\.\\s*", "", names(file_tables[3])))),
       x = "Number of applications sent",
       y = "Probability of receiving a job offer") +
  scale_y_continuous(limits = c(0,40)) +
  theme(plot.title = element_text(size = 8)) +
  common_theme


# Compile all plots
grid.arrange(p1, p2, p3, layout_matrix = rbind(
    c(1, 2), # Plot 1 (left column, top row), Plot 3 (right column)
    c(3, 2)  # Plot 2 (left column, bottom row), Plot 3 (right column)
  )) +
  common_theme

```

It turns out that the 2018 supplement was also run in 2022, giving us
two sets of years to compare (including pre- and post-Covid). The below
looks at the [raw
data](https://www.census.gov/data/datasets/time-series/demo/cps/cps-supp_cps-repwgt/cps-unemployment.2022.html#list-tab-1269561637)
that underlies the plotting immediately above, plus the additional data
from 2022. Below find a preliminary scatter plot of applications sent
versus unemployment duration. Each individual is asked how many
applications they sent in the last two months (two-month periods are
indicated by the grey gridlines, for reference). This does NOT include
data in on the job search.

**Data Source:** Unemployment Insurance Nonfilers Supplement conducted
in 2018 (n = 3,268) & 2022 (n = 1,901) where individuals who are
unemployed but have not filed for unemployment insurance are asked the
following:

![Survey Question: Unemployment
Duration](CPS_BLS_Supplement_18_22/udur_survey_question.png)

![Survey Question: Applications
Sent](CPS_BLS_Supplement_18_22/apps_sent_question.png)

```{r, echo=FALSE, fig.height = 7, fig.width = 10, cache = TRUE}
source(here('data/behav_params/CPS_BLS_Supplement_18_22/cps_bls_supp_cleaning.R'))

bea_temp <- bea_2022 %>%
  select(HRHHID, PEA1, PRUNEDUR, HEFAMINC, PESEX, PTDTRACE, PRDTOCC1, PEEDUCA, PESEX, PRTAGE) %>%
  mutate(year = 2022) %>%
  rbind(., select(mutate(bea_2018, year = 2018), HRHHID, PEA1, PRUNEDUR, HEFAMINC, PESEX, PTDTRACE, PRDTOCC1, PEEDUCA, PESEX, PRTAGE, year)) %>%
  mutate(year = as.factor(year)) %>%
  filter(PEA1 >= 0 & PRUNEDUR > 0) %>%
  mutate(PEA1 = factor(PEA1, levels = c(0,1,2,3,4),
                       labels = c("0",
                                  "1 to 10",
                                  "11 to 20",
                                  "21 to 80",
                                  "81 or more")),
         PRUNEDUR_brackets = case_when(PRUNEDUR < 5 ~ "<5 weeks",
                                       PRUNEDUR >= 5 & PRUNEDUR <= 14 ~ "05-14 weeks",
                                       PRUNEDUR > 14 & PRUNEDUR <= 26 ~ "15-26 weeks",
                                       PRUNEDUR > 26 ~ "27 weeks+"),
         PRUNEDUR2 = PRUNEDUR^2,
         PRUNEDUR_MO = floor(PRUNEDUR/4),
         PRUNEDUR_MO2 = PRUNEDUR_MO^2,
         white = as.numeric(PTDTRACE == 1),
         black = as.numeric(PTDTRACE == 2),
         asian = as.numeric(PTDTRACE == 4),
         female = as.numeric(PESEX == 2),
         no_hs = as.numeric(PEEDUCA < 39),
         hs_no_bachelors = as.numeric(PEEDUCA >= 39 & PEEDUCA <= 42),
         bachelors_plus = as.numeric(PEEDUCA > 42),
         age_29_less = as.numeric(PRTAGE < 30),
         age_30_39 = as.numeric(PRTAGE >= 30 & PRTAGE < 40),
         age_40_54 = as.numeric(PRTAGE >= 40 & PRTAGE < 55),
         age_54_64 =  as.numeric(PRTAGE >= 55 & PRTAGE < 65),
         age_65_plus =  as.numeric(PRTAGE >= 65)) %>%
  group_by(year, PRUNEDUR_brackets) %>%
  mutate(mean_inc = mean(HEFAMINC)) %>%
  ungroup

bea_temp %>%
  ggplot() +
  geom_jitter(aes(x= PRUNEDUR, y = PEA1, colour = year)) +
  labs(x = "Unemployment Duration (Weeks)", y = "Number of applications sent in the last two months",
       title = "Applications sent vs. Time Spent Unemployed: 2022 & 2018",
       subtitle = "Grey gridlines align with 2-month/8-week intervals. N = 2,896 (2018) & 1,677 (2022)") +
   theme(panel.grid.minor = element_line(colour="grey", linetype = "dashed"),
         panel.grid.major = element_blank()) +
 scale_x_continuous(minor_breaks = seq(0, 120, 8)) +
  scale_color_manual(values = c("darkblue", "steelblue")) +
  common_theme

# bea_temp %>%
#   ggplot() +
#   geom_density(aes(x = HEFAMINC, fill = PRUNEDUR_brackets), alpha = 0.5) +
#   labs(x = "Income Bracket", y = "Count",
#        title = "Histogram of Income by Unemployment Duration")
# 
# bea_temp %>%
#   ggplot() +
#   geom_violin(aes(x = PRUNEDUR_brackets, y = HEFAMINC, fill = PRUNEDUR_brackets), alpha = 0.5) +
#   labs(x = "Unemployment Duration", y = "Income Bracket",
```

Below, I display the results of an exploration of the probability of
reporting a specific number of applications sent (in the bins as in the
survey question above) using various specifications of an ordinal
logistic regression. I test specifications varying three different
model parameters: 
1. link function                 
2. linear vs. quadratic unemploymentduration,              
3. with and without demographic control variables (education,
gender, age, family income - race excluded because of lack of
statistical significance though this can be revisited.)              

We estimate an ordinal logistic regression model for reported applications sent
$Y_i in {0, 1, 2, 3, 4}$ testing four different link
functions: the complementary log-log (cloglog),
logistic, log-log, and probit link functions.
Let $X_i^\top \beta$ denote the predictor variable. The cumulative
probability of observing response category $j$ or below,
$\Pr(Y_i \leq j \mid X_i)$, is modeled as follows for each link
function:

\begin{align*}
\text{Complementary log-log (cloglog):} \quad & \Pr(Y_i \leq j \mid X_i) = 1 - \exp\left( -\exp\left( \tau_j - X_i^\top \beta \right) \right) \\
\text{Logistic (logit):} \quad & \Pr(Y_i \leq j \mid X_i) = \frac{1}{1 + \exp\left( -(\tau_j - X_i^\top \beta) \right)} \\
\text{Loglog:} \quad & \Pr(Y_i \leq j \mid X_i) = \exp\left( -\exp\left( -(\tau_j - X_i^\top \beta) \right) \right) \\
\text{Probit:} \quad & \Pr(Y_i \leq j \mid X_i) = \Phi(\tau_j - X_i^\top \beta)
\end{align*}

Here, $\Phi(\cdot)$ denotes the cumulative distribution function of the
standard normal distribution. The estimated coefficients $\beta$ are
interpreted conditional on the choice of link function where $X_i$ is either:

$X_i = \left( \text{Unemp.Dur.}_i \right)$

$X_i = \left( \text{Unemp.Dur.}_i^2 \right)$

$X_i = \left( \text{Unemp.Dur.}_i, \text{Unemp.Dur.}_i^2 \right)$

with and without control variables (education, gender, age, family income).

Assumptions about the probability distribution of the errors associated with each link function:              
- *Logit:* good when the response behavior is symmetric around the middle category.             
- *Probit:* When you’re assuming a normal latent error distribution or want closer fit to Gaussian processes.             
- *Complementary log-log:* When the likelihood of being in a higher category increases sharply but asymmetrically, or you expect hazard-like dynamics.             
- *Log-log:* When early categories are of more importance and need sharper separation.             

*Preliminary hypothesis:* Best fit will be with a complementary log-log as we care more about distinguishing between lower-level bins and there are few observations in the highest-level bins. 


```{r, echo=FALSE, fig.height = 6, fig.width = 10, cache = TRUE}
#        title = "Distribution of Family Income by Unemployment Duration")

bea_temp <- bea_temp %>% 
  mutate(PEA_fct = case_when(PEA1 == "0" ~ 0,
                   PEA1 == "1 to 10" ~ 1,
                   PEA1 == "11 to 20" ~ 2, 
                   PEA1 == "21 to 80" ~ 3,
                   PEA1 == "81 or more" ~ 4)) 

bea_temp$PEA_fct <- ordered(
  bea_temp$PEA1, 
  levels = c("0", "1 to 10", "11 to 20", "21 to 80", "81 or more")
)

control_vars <- c("female", "no_hs", "hs_no_bachelors",
                  "age_29_less", "age_30_39", "age_40_54", "age_54_64", "HEFAMINC")

link_methods <- c("logistic", "probit", "cloglog", "loglog")
control_statuses <- c("no_controls", "with_controls")

plots_final <- list()
# Store AICs
aic_results <- data.frame()

for (mod in c("PRUNEDUR_MO", "PRUNEDUR_MO2", "PRUNEDUR_MO + PRUNEDUR_MO2")) {
  
  combined_data <- data.frame()
  
  for (method in link_methods) {
    for (control_status in control_statuses) {
      
      # Model formula
      formula_str <- if (control_status == "with_controls") {
        paste0("PEA_fct ~ ", mod, " + ", paste(control_vars, collapse = " + "))
      } else {
        paste0("PEA_fct ~ ", mod)
      }
      
      # Fit model
      model <- polr(
        as.formula(formula_str),
        data = bea_temp,
        method = method,
        Hess = TRUE
      )
      
      aic_results <- rbind(aic_results, tibble(
        Duration_Var = mod,
        Method = method,
        Controls = ifelse(control_status == "with_controls", "With Controls", "No Controls"),
        AIC = AIC(model),
        mod_res = list(model)
      ))
      
      # Prediction data
      new_data <- data.frame(PRUNEDUR_MO = seq(
        min(bea_temp$PRUNEDUR_MO, na.rm = TRUE),
        max(bea_temp$PRUNEDUR_MO, na.rm = TRUE),
        length.out = 100
      ))
      
      if (mod != "PRUNEDUR_MO") {
        new_data$PRUNEDUR_MO2 <- new_data$PRUNEDUR_MO^2
      }
      
      # Add average control values
      for (var in control_vars) {
        new_data[[var]] <- mean(bea_temp[[var]], na.rm = TRUE)
      }
      
      # Predict
      probs <- predict(model, newdata = new_data, type = "probs")
      
      # Format
      probs_long <- new_data %>%
        select(PRUNEDUR_MO) %>%
        bind_cols(as.data.frame(probs)) %>%
        pivot_longer(cols = -PRUNEDUR_MO, names_to = "Category", values_to = "Probability") %>%
        mutate(
          Method = method,
          Controls = ifelse(control_status == "with_controls", "With Controls", "No Controls")
        )
      
      combined_data <- bind_rows(combined_data, probs_long)
    }
  }
  
  # Create the plot with facet by control setting (2 subplots), within each facet multiple methods
  p <- ggplot(combined_data, aes(x = PRUNEDUR_MO, y = Probability, color = Method)) +
    geom_line(size = 0.9) +
    facet_grid(Category ~ Controls, scales = "free_y") +
    labs(
      title = paste("Predicted Application Probabilities (", mod, ")", sep = ""),
      x = "Unemployment Duration (Months)",
      y = "Predicted Probability",
      color = "Link Function"
    ) +
    theme_minimal() +
    theme(legend.position = "bottom")+
  common_theme

  plots_final[[mod]] <- p
}
# View plot for PRUNEDUR_MO
print(plots_final[["PRUNEDUR_MO"]])

# View plot for PRUNEDUR_MO2
print(plots_final[["PRUNEDUR_MO2"]])

# View plot for PRUNEDUR_MO2
print(plots_final[["PRUNEDUR_MO + PRUNEDUR_MO2"]])
```

Using an AIC information criterion to compare the fit across all models, the following results are clear:            
1. Models with control variables consistently perform better than those without.                                        
2. Looking at the plots above, the relationship between unemployment duration and the predicted probability of reporting each application effort bin is very consistent except in the case of the log-log link function (blue in the panels above). In the plot below comparing the AIC the log-log link function (represented by the square symbol below) is consistently worse than all other link functions. This indicates consistency in the results reported above. Intuitively, the log-log link function is likely to be an unreasonable fit for the latent variable as we care more about shifts in the lower-level categories than higher-level categories.                  
3. A complementary log-log specification for the latent variable is most suitable. This follows logically from the fact that the probability of being in the highest-level categories is relatively low.             
4. Finally, a specification with a linear and quadratic estimator is consistently better than either the specification with simply a linear OR quadratic unemployment duration estimator indicating that the probability distributions represented in the final panel above are likely to be the best fit.          


*Result:* For each additional quarter of unemployment, an individual’s odds of dropping to a lower-level application category decreases by ~.1%. This is statistically significant across all specifications at the 0.1% level.


```{r, echo=FALSE, fig.height = 6, fig.width = 8, cache = TRUE}
# Normalize AIC relative to the best within each duration variable
aic_results <- aic_results %>%
  #group_by(Duration_Var) %>%
  mutate(Relative_AIC = AIC - min(AIC)) %>%
  ungroup() %>% 
  mutate(duration = case_when(Duration_Var == "PRUNEDUR_MO" ~ "Linear",
                   Duration_Var == "PRUNEDUR_MO2" ~ "Quadratic",
                   Duration_Var == "PRUNEDUR_MO + PRUNEDUR_MO2" ~ "Lin-Quadratic"))

ggplot(aic_results, aes(x = Relative_AIC, color = Controls, shape = Method, y = duration)) +
  geom_point(size = 4) + #stat = "identity", position = position_dodge(width = 0.8)) +
  #facet_wrap(~Duration_Var) +
  labs(
    title = "Relative AIC Across Link Functions and Linear vs. Quadratic Unemployment Duration",
    x = "Relative AIC (compared to best-fit model)",
    y = "w. or w.o Controls",
    color = "Link Function",
    shape = "Transformation of Unemp. Dur."
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  common_theme
```


```{r, echo=FALSE, fig.height = 8, fig.width = 10, cache = TRUE}
# View best model row
best_row <- aic_results %>% arrange(AIC) %>% slice(1)

# Access the stored model object
best_model <- best_row$mod_res[[1]]

create_data <- function(length = NULL){
  if(is.null(length)){
    # Prediction data
      dat <- data.frame(PRUNEDUR_MO = seq(
        min(bea_temp$PRUNEDUR_MO, na.rm = TRUE),
        max(bea_temp$PRUNEDUR_MO, na.rm = TRUE),
        length.out = max(bea_temp$PRUNEDUR_MO, na.rm = TRUE) + 1
    ))
  }else{
        # Prediction data
      dat <- data.frame(PRUNEDUR_MO = seq(
        min(bea_temp$PRUNEDUR_MO, na.rm = TRUE),
        length,
        length.out = length + 1))
  }
  
  dat$PRUNEDUR_MO2 <- dat$PRUNEDUR_MO^2
  
  # Add average control values
  for (var in control_vars) {
    dat[[var]] <- mean(bea_temp[[var]], na.rm = TRUE)
  }
  
  # Predict
  probs <- predict(best_model, newdata = dat, type = "probs") 
  
  dat <- dat %>% 
      select(PRUNEDUR_MO) %>%
            bind_cols(as.data.frame(probs)) %>%
            pivot_longer(cols = -PRUNEDUR_MO, names_to = "Category", values_to = "Probability") 

  return(dat)
}

new_data <- create_data()
new_data_long <- create_data(200)

identical(new_data, slice(new_data_long, 1:nrow(new_data)))
all.equal(new_data, mutate(tibble(read.csv(here("data/behav_params/CPS_BLS_Supplement_18_22/app_probs.csv"))[,-1]), PRUNEDUR_MO = as.numeric(PRUNEDUR_MO)))


limits_df <- new_data %>%
  group_by(Category) %>%
  summarise(
    center = mean(Probability),
    range = max(Probability) - min(Probability),
    width = 0.12  # or use: range * 1.2
  ) %>%
  mutate(
    y_min = pmax(0, center - width / 2),
    y_max = pmin(1, center + width / 2)
  )

# Merge limits into the plot data
plot_data <- left_join(new_data, limits_df, by = "Category")
plots <- plot_data %>%
  split(.$Category) %>%
  lapply(function(df_cat) {
    ggplot(df_cat, aes(x = PRUNEDUR_MO, y = Probability)) +
      geom_line(size = 0.9, color = "darkgrey") +
      labs(title = paste0("Bin: ", unique(df_cat$Category), " applications"), x = "Unemployment Duration (Months)") +
      coord_cartesian(ylim = c(unique(df_cat$y_min), unique(df_cat$y_max))) +
      theme_minimal() +
      theme(
        plot.title = element_text(size = 10, face = "bold"),
        axis.title.y = element_blank()
      ) +
  common_theme
  })

p1 <- wrap_plots(plots, ncol = 1) +
  plot_annotation(
    title = "Predicted Application Probabilities (Manually Normalized Y-Axis Ranges)",
    theme = theme(plot.title = element_text(size = 14, face = "bold")) +
  common_theme
  ) 
  
p2 <- new_data %>% 
    ggplot(aes(x = PRUNEDUR_MO, y = Probability, fill = Category)) +
    geom_area(stat = "identity") +
    scale_fill_brewer(palette = "Set2") +
    labs(y = "Probability of Sending X Applications (Binned)", x = "Unemployment Duration (Months)", title= paste0("Predicted Probabilities of Apps Sent by Unemployment Duration"))+
  common_theme


(p1 | p2) + plot_annotation(title = "Predicted Probabilities of Application Effort by Unemployment Duration",
      subtitle = "N = 5,169\nBureau of Labor Statistics Data reported in 2018 and 2022.\nEstimated using an ordinal logistic regression in which the outcome variables are bins of applications sent.\nUnemployment duration enters quadratically w. sociodemographic controls.\nControls: Education, Age, Gender, Family Income. Race excluded because of lack of statistical significance.\nLink function: Complementary log-log function selected using AIC comparison on 4 alternative link functions.",     theme = theme(
      plot.title = element_text(size = 18, face = "bold"),
      plot.subtitle = element_text(size = 12)
    ) +
  common_theme
  )

# new_data %>% 
#   write.csv(., here("data/behav_params/CPS_BLS_Supplement_18_22/app_probs.csv"))

# new_data_long %>%
#   write.csv(., here("data/behav_params/CPS_BLS_Supplement_18_22/app_probs_long.csv"))

```

#### Validation: Mukoyama et al. Job Search and the Business Cycle

[Mukoyama: Job Search Over the Business
Cycle](https://www.aeaweb.org/articles?id=10.1257/mac.20160202)

```{r, echo = FALSE, fig.height = 8, fig.width = 10, cache = TRUE}

source(here("data/behav_params/Mukoyama_Replication/mukoyama_replication_analysis.R"))

```

### Reservation Wage Adjustment {.tabset}

```{r, child = "cps_displaced_worker_supplement/cps_disc_worker_vignette.Rmd"}
```

### OTJ Search {.tabset}

#### Eeckhout et al. 2019 Unemployment Cycles

[Source](https://www.aeaweb.org/articles?id=10.1257/mac.20180105)

![Employed Search Effort Fit](Eeckhout_Replication/emp_search_effort.png)


```{r, echo = FALSE, fig.height = 8, fig.width = 10, cache = TRUE}

source(here('data/behav_params/Eeckhout_Replication/eeckhout_extended_replication.R'))

```

### Learning Rate {.tabset}

#### Mueller et al. Job Seekers' Perceptions and Employment Prospects: Heterogeneity, Duration Dependence and Bias

[Mueller et al: Job Seekers' Perceptions and Employment
Prospects](https://www.aeaweb.org/articles?id=10.1257/aer.20190808)

*The authors claim to disentangle the effects of duration dependence and
dynamic selection by using job seekers' elicited beliefs about
job-finding. Assuming (and confirming empirically) that job-seekers have
realistic initial beliefs about job-finding they isolate the
heterogeneity in jobseekers from true duration dependence. Ultimately,
they find that dynamic selection selection explains most of the negative
duration dependence (rather than pure, true duration dependence).*

*Findings: Results are remarkably consistent even when including
additional data from 2019-2024.*

We aim to include this information in our theoretical model of the job
search effort as a learning rate (ie. individuals learn about their
re-employment probability with repeated failures in the job search).

```{r, echo = FALSE, fig.height = 8, fig.width = 10, cache = TRUE}

source(here("data/behav_params/Mueller_Replication/mueller_repl_analysis_extended_samples.R"))

```

## Discarded Analyses {.tabset}

<!-- I first focus on replicating and extending the empirical analysis that speaks to the three determinants above (dynamic selection, duration dependence, search effort) -->

1.  (Replicated with additional data for unemployed jobseekers)
    [**Mukoyama et al. 2018: Job Search Over the Business
    Cycle**](https://www.aeaweb.org/articles?id=10.1257/mac.20160202)

*They provide a novel measure of job search effort exploiting the
American Time Use and Current Population Surveys which can be reduced to
just the intensive margin (changes in search effort by worker!). At the
moment, I think this will be the most useful input for our model.*

*Abstract: We examine the cyclicality of search effort using
time-series, cross-state, and individual variation and find that it is
countercyclical. We then set up a search and matching model with
endogenous search effort and show that search effort does not amplify
labor market fluctuations but rather dampens them. Lastly, we examine
the role of search effort in driving recent unemployment dynamics and
show that the unemployment rate would have been 0.5 to 1 percentage
points higher in the 2008–2014 period had search effort not increased.*

4.  **Survey of Consumer Expectations Reservation Wages, Accepted Wages,
    and Wage Expectations** The data is unfortunately sparse and linking
    outcomes to reservation wages is difficult. However, in a
    cross-sectional setting we are able to deduce some weak
    relationships between Unemployment Duration and Absolute Reservation
    Wages and Wage Expectations.\*

<!-- 3. (Forthcoming) **[Kroft et al. 2016: Long-Term Unemployment and the Great Recession: The Role of Composition, Duration Dependence, and Nonparticipation](https://www.jstor.org/stable/26588430)** -->

<!-- *Abstract: We explore the role of composition, duration dependence, and labor force nonparticipation in accounting for the sharp increase in the incidence of long-term unemployment (LTU) during the Great Recession. We show that compositional shifts account for very little of the observed increase in LTU. Using panel data from the Current Population Survey for 2002–7, we calibrate a matching model that allows for duration dependence in unemployment and transitions between employment, unemployment, and nonpartici- pation. The calibrated model accounts for almost all of the increase in LTU and much of the observed outward shift in the Beveridge curve between 2008 and 2013.* -->

### Reservation Wages

Exploring the effect of unemployment duration on reservation wages,
accepted wages, and expected wage offers.

**Survey of Consumer Expectations Reservation Wages, Accepted Wages, and
Wage Expectations** (2014-2022) *The data is unfortunately sparse and
linking outcomes to reservation wages is difficult. However, in a
cross-sectional setting we are able to deduce some weak relationships
between Unemployment Duration and Absolute Reservation Wages and Wage
Expectations.*

```{r, fig.height = 8, fig.width = 10}

source(here("data/behav_params/SCE Labour Market Survey/sce_res_wage_analysis.R"))

```

<!-- ## Kroft et al. Long-Term Unemployment and the Great Recession: The Role of Composition, Duration Dependence, and Nonparticipation -->

<!-- [Kroft et al. Long-Term Unemployment and the Great Recession](https://www.jstor.org/stable/26588430) -->

<!-- ```{r, echo = FALSE} -->

<!-- ``` -->

<!-- ## Own work on microdata... {.tabset} -->

### Survey on Consumer Expectations - Job Search Supplement

The Federal Reserve Bank of New York compiles the nationally
representative Survey on Consumer Expectations annually in October.
Since 2013, they have run a Job Search Supplement which includes
questions on the time spent searching for work, and unemployment
duration. The job search supplement has plenty more questions that we
can look at incorporating, listed
[here](https://www.newyorkfed.org/medialibrary/Interactives/sce/sce/downloads/data/SCE-Labor-Market-Survey-Data-Codebook.pdf?sc_lang=en).
For now, I plot the relationship between time spent searching and time
out of work. The table below also indicates the number of people
unemployed in the dataset and the number of people unemployed and
searching.

```{r, echo=FALSE, results = 'asis', cache = TRUE}

source(here('data/behav_params/SCE Job Search Survey/sce_job_search_cleaning.R'))

# Extract question types
categories <- sce_job_search_full %>%
  names %>%
  grep("[0-9]", ., value = TRUE) %>%
  lapply(., function(x) str_split_i(x, "(?=\\d)", i = 1)) %>%
  unlist %>%
  unique %>%
  grep("under", ., value = TRUE, invert = TRUE)

codebook <- pdf_text(here('data/behav_params/SCE Job Search Survey/SCE-Labor-Market-Survey-Data-Codebook.pdf')) %>%
  lapply(., function(x) str_split(x, "\n")) %>%
  unlist %>%
  .[.!="" & !grepl("                                                      ", .)]

# Creates list of categories of questions in job search survey
labels = list("l" = "GENERAL LABOR MARKET QUESTIONS",
              "jh" = "JOB SEARCH FOR MOST RECENT JOB",
              "ec" = "ADDITIONAL EMPLOYMENT INFORMATION",
              "es" = "ADDITIONAL INFORMATION FOR THE SELF EMPLOYED",
              "eo" = "ADDITIONAL INFORMATION FOR THE NON-EMPLOYED",
              "el" = "ADDITIONAL INFORMATION ON THE MOST RECENT JOB",
              "js" = "JOB SEARCH BEHAVIOR",
              "rw" = "RESERVATION WAGE ELICITATION",
              "tp" = "BENEFITS AND TRANSFER PAYMENTS HISTORY",
              "hh" = "SPOUSE/PARTNER EMPLOYMENT STATUS")

# Split the codebook based on the 10 higher-level categories present in the Job Search Survey
list_splitters <- lapply(categories, toupper) %>% unlist %>% paste0(., ". ", labels)
is_start <- codebook %in% list_splitters
group_index <- cumsum(is_start)

# Split the list into sublists based on the grouping index
sublists <- split(codebook, group_index)


```

```{r, echo=FALSE, cache = TRUE}

library(ggbreak)

sce_job_search_free <- sce_job_search %>%
  select(responseid,
         year,
         l7_days_spent_searching,
         l7_days_spent_searching_transformed,
         l8_months_no_work) %>%
   # Removes one extreme outlier at 600
  filter(l8_months_no_work < 400,
         l7_days_spent_searching_transformed < 2000)


sce_job_search %>%
  group_by(year) %>%
  summarise(n_obs_unemployed = n()) %>%
  left_join(., summarise(group_by(sce_job_search_free, year), n_obs_unemp_searching = n()), by = "year") %>%
  rename('Year' = year,
         'N Unemployed' = n_obs_unemployed,
         'N Unemp & Searching' = n_obs_unemp_searching) %>%
  kable()

sce_job_search_free %>%
    pivot_longer(!c(responseid, year)) %>%
  filter(name != "l7_days_spent_searching_transformed") %>%
  ggplot() +
  geom_histogram(aes(x = value, fill = name)) +
  facet_wrap(~name, scales = "free_x", ncol = 1, labeller = labeller(name = rename_fun)) +
  #scale_x_break(c(3000, 15000)) +
  theme(legend.position = "none") +
  labs(title = "Histogram of time spent searching and out of work.", x = "Time (days or months)", y = "Count", caption = "N = 366")


sce_job_search_free %>%
  mutate(l8_days_no_work = l8_months_no_work*30.5) %>%
  ggplot(aes(x = log(l8_days_no_work), y = log(l7_days_spent_searching))) +
  geom_jitter(aes(color = as.factor(year))) +
  geom_abline(intercept = 0, slope = 1, size = 0.5, linetype = "dashed", color = "darkgrey") +
  #stat_lm() +
  labs(x = "Total time out of work (log days)", y = "Total time spent searching (log days)", title = "Time dedicated to searching versus time spent unemployed",
       subtitle = "Blue line indicates best fit line. Grey dashed line indicates 45 degree line. N = 366") +
  common_theme

```

### On the job search

```{r, echo=FALSE, cache = TRUE}

sce_job_search_emp %>%
  ggplot() +
  geom_density(aes(x = l7_days_spent_searching, fill = as.factor(l1a_text)), alpha = 0.5) +
  labs(x = "Days spent searching", y = "Count",
       title = "Histogram of Days Spent Searching by Unemployment Status") +
  common_theme

```

### (TBD) American Time Use Survey

The American Time Use Survey gives no indication of time spent in
unemployment. It shows how much time is spent searching but does not
link to time spent in unemployment. Therefore, I prioritised the
datasets above. [Krueger & Mueller
2010](https://www.sciencedirect.com/science/article/abs/pii/S0047272709001625)
impute duration spent unemployed from the ATUS in the following way
which could be worth considering.

"Unfortunately, the ATUS interview does not collect information on
unemployment duration. Consequently, we derive unemployment duration by
taking the unemployment duration reported in the last CPS interview and
adding the number of weeks that elapsed between the CPS interview and
the ATUS interview. Eighty-six percent of the ATUS interviews were
conducted within 3 months of the last CPS interview. For those who were
not unemployed at the time of the CPS interview, we impute duration of
unemployment by taking half the number of weeks between the CPS and the
ATUS interviews. We do not show the weekly LOWESS plot for 13 weeks or
less, but simply report the average time allocated to search, as the
imputed unemployment duration are quite noisy for those who become
unemployed after their last CPS interview."

<!-- ### Occupational Restructuring -->

<!-- ```{r, cache = TRUE} -->

<!-- #read.xls(here("data/macro_vars/OEWS/") -->

<!-- ``` -->
